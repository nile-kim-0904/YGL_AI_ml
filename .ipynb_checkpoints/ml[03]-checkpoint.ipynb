{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4e3090a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version -  1.20.3\n",
      "pandas version -  1.3.4\n",
      "seaborn version -  0.11.2\n",
      "matplotlib version -  3.4.3\n",
      "sklearn version -  0.24.2\n",
      "missingno version -  0.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('numpy version - ',np.__version__)\n",
    "print('pandas version - ',pd.__version__)\n",
    "print('seaborn version - ',sns.__version__)\n",
    "print('matplotlib version - ',matplotlib.__version__)\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, make_scorer, precision_recall_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "print('sklearn version - ',sklearn.__version__)\n",
    "\n",
    "import missingno as msno \n",
    "print('missingno version - ',msno.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78addea",
   "metadata": {},
   "source": [
    "#### 분류 모델의 성능 평가\n",
    "- 정확도: 실 데이터와 예측 데이터가 얼마나 같은지를 판단하는 지표\n",
    "- 문제점 why? - 이진분류의 경우 모델의 성능을 왜곡할 수 있다\n",
    "    - 데이터의 불균형\n",
    "- 해결책: F1 Score(Precision, Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96ccfe9",
   "metadata": {},
   "source": [
    "#### 분류 모델 성능 평가를 위한 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c73f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP(target=1, predict=1)\n",
      "TN(target=0, predict=0)\n",
      "FP(target=0, predict=1) -> type 1 error\n",
      "FN(target=1, predict=0) -> type 2 error\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TP(target = 1, prediction = 1) 3\n",
      "TN(target = 0, prediction = 0) 0\n",
      "FP(target = 0, prediction = 1) 3\n",
      "FN(target = 1, prediction = 0) 4\n"
     ]
    }
   ],
   "source": [
    "print('TP(target=1, predict=1)')\n",
    "print('TN(target=0, predict=0)')\n",
    "print('FP(target=0, predict=1) -> type 1 error')\n",
    "print('FN(target=1, predict=0) -> type 2 error')\n",
    "\n",
    "target = [1,0,0,1,1,1,0,1,1,1]\n",
    "prediction = [0,1,1,1,1,0,1,0,1,0]\n",
    "\n",
    "tp = tn = fn = fp = 0\n",
    "\n",
    "for idx in range(len(target)):\n",
    "    print(idx)\n",
    "    #TP\n",
    "    if ((target[idx]==1) and (prediction[idx]==1)):\n",
    "        tp += 1\n",
    "    #TN\n",
    "    elif ((target[idx]==0) and (prediction[idx]==0)):\n",
    "        tn += 1\n",
    "    #FP\n",
    "    elif ((target[idx]==0) and (prediction[idx]==1)):\n",
    "        fp += 1\n",
    "    #FN\n",
    "    elif ((target[idx]==1) and (prediction[idx]==0)):\n",
    "        fn += 1\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "print('\\n\\n\\n')\n",
    "print('TP(target = 1, prediction = 1)',tp)\n",
    "print('TN(target = 0, prediction = 0)',tn)\n",
    "print('FP(target = 0, prediction = 1)',fp)\n",
    "print('FN(target = 1, prediction = 0)',fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cffda48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy -  0.3\n",
      "recall -  0.42857142857142855\n",
      "precision -  0.5\n",
      "f1 score -  0.4615384615384615\n",
      "\n",
      "confusion_matrix - \n",
      " [[0 3]\n",
      " [4 3]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy - ',accuracy_score(target,prediction))\n",
    "print('recall - ',recall_score(target,prediction))\n",
    "print('precision - ',precision_score(target,prediction))\n",
    "print('f1 score - ',f1_score(target,prediction))\n",
    "print()\n",
    "print('confusion_matrix - \\n',confusion_matrix(target,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba12e2",
   "metadata": {},
   "source": [
    "- 정밀도(Precision): TP / (FP + TP)\n",
    "- 상대적으로 정밀도가 더 중요한 지표인 경우의 모델? - 스팸메일\n",
    "- 재현율(Recall): TP / (FN + TP)\n",
    "- 상대적으로 재현율 더 중요한 지표인 경우의 모델? - 의학(암진단), 금융(사기판독)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4525f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터 로드\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('1. 데이터 로드')\n",
    "print()\n",
    "titanic_frm = pd.read_csv('data/titanic_train.csv')\n",
    "display(titanic_frm)\n",
    "\n",
    "titanic_frm['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f81e86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. target, feature로 데이터 분리\n",
      "target type -  <class 'pandas.core.series.Series'>\n",
      "feature type -  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print('2. target, feature로 데이터 분리')\n",
    "\n",
    "titanic_target = titanic_frm['Survived']\n",
    "titanic_feature = titanic_frm.drop(['Survived'],axis=1)\n",
    "\n",
    "print('target type - ',type(titanic_target))\n",
    "print('feature type - ',type(titanic_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "555372c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. 전처리 요구사항 - \n",
      "불필요한 피처 제거 - PassengerId, Name, Ticket\n",
      "결측값 처리, 시각적 확인 - Age는 평균, Cabin은 N, Embarked는 N\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0         3    1  22.000000      1      0   7.2500      7         3\n",
       "1         1    0  38.000000      1      0  71.2833      2         0\n",
       "2         3    0  26.000000      0      0   7.9250      7         3\n",
       "3         1    0  35.000000      1      0  53.1000      2         3\n",
       "4         3    1  35.000000      0      0   8.0500      7         3\n",
       "..      ...  ...        ...    ...    ...      ...    ...       ...\n",
       "886       2    1  27.000000      0      0  13.0000      7         3\n",
       "887       1    0  19.000000      0      0  30.0000      1         3\n",
       "888       3    0  29.699118      1      2  23.4500      7         3\n",
       "889       1    1  26.000000      0      0  30.0000      2         0\n",
       "890       3    1  32.000000      0      0   7.7500      7         2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabin의 경우 앞 문자 하나에 대해서 레이블 인코딩만 진행!!\n",
      "레이블 인코딩 - Sex, Cabin, Embarked\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0         3    1  22.000000      1      0   7.2500      7         3\n",
       "1         1    0  38.000000      1      0  71.2833      2         0\n",
       "2         3    0  26.000000      0      0   7.9250      7         3\n",
       "3         1    0  35.000000      1      0  53.1000      2         3\n",
       "4         3    1  35.000000      0      0   8.0500      7         3\n",
       "..      ...  ...        ...    ...    ...      ...    ...       ...\n",
       "886       2    1  27.000000      0      0  13.0000      7         3\n",
       "887       1    0  19.000000      0      0  30.0000      1         3\n",
       "888       3    0  29.699118      1      2  23.4500      7         3\n",
       "889       1    1  26.000000      0      0  30.0000      2         0\n",
       "890       3    1  32.000000      0      0   7.7500      7         2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABbcAAAKECAYAAAA0SAf3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABAMElEQVR4nO3debhu53g/8O+dRGIuRc20WgQtNVNjUFptlZpaQ1Bpq5T6hZpLqLFmjdBBDU1UTaFas8Y8RBFqnksQak5EhOT+/fGsLW93T5J9Mpz3PCefz3Wda++91rv3ec7OynrX+q77uZ/q7gAAAAAAwEx2W/cAAAAAAABgewm3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAOAsrKpkhEzJgQsAAAAAZ0FVdY4k6e4Tq2r3dY8HtpdwGwAAAADOYqpqjyRvqKrPJEl3nyDgZjbCbQAAAAA469k9yaFJzl9V704E3MynunvdYwAAAAAAdrCq2jPJPZIckOSL3X3dZfvu3X3COscGW6FyGwAAAADOQpaWJOnu45N8NMlLk1y7qt64bFfBzRRUbgMAAADAWURVVS+BYFW9NMlFk5wjyQWTXCrJu7v7+st+Fdzs1FRuAwAAAMBZxEqw/dQkN0jykCQ3SXKFJI9KchU9uJmFcBsAAAAAzkKq6mxJrpXksCTv7+7vd/cPkzwto//2dbQoYQbCbQAAAAA4a9kzyS8kOa67j69h9+7+QZLnJDkiyc2q6qPJCLjXN1Q4ecJtAAAAANhFVVVt3raE2K9M8ltVdYOlVcmJVbVbdx+b5BNJ3pZkt6r6hR07Ytg64TYAAAAA7IKWauyNHtu7VdWeK7tfm+ToJA+rquv0cGJVXSjJeZO8KMm1u/sLO37ksDW1HN8AAAAAwC5iCbZPWD5/VJJrJjlfRlX2I7v7a1X1x0kekeSHSQ5KckKSGybZJ8nVu/tL6xg7bJVwGwAAAAB2UVX18iTXTvLmJGdLcv0knWT/7j60qm6bZN8kv5PkO0m+kuSu3f3hNQ0ZtmyPdQ8AAAAAADjjVdV9k1w1yZ2SvLu7T6iq38hoSXL5pcf2K6rqVUkumqSSHNPd31nboGE7CLcBAAAAYNd0tSSfTfKRJdi+bJKDk7wkyTO7+8QkWdqXHLm+YcJpY0FJAAAAAJhcVe2+8vk5qmq3JFdI8t3u/l5V7Z3kfRntSf6ou39YVY+sqkevachwugm3AQAAAGBSVVXJT6uvU1XPS3K9pSr7LUluVlW3TvKOnBRs/6CqLpXkSknOX1VnX8vg4XQSbgMAAADAZKpqj6Vndm9UbVfVNZPcJsl/LS97U5JvJHlZkg929x26++iqunCSA5JcI8mzuvu4Hf8vgNNPz20AAAAAmMhSaf3qJIdX1QEbVdsZhaxnS7JnknT3W6vqwCT3T3LZqrpHkksm+dUkN0pyk+7+7A4ePpxhhNsAAAAAMJezJ7lEkssnObqqnroE3OdM8sMkx1bVnt19fHc/u6q+nuTWSZ6Q5KgkH0py/e7+xHqGD2eM6u51jwEAAAAA2IKlFcmJVXXBJK9Ictkkz0rylCS/nuRvu/tSJ/O9F+jub1XVXt39ox03ajhzqNwGAAAAgHlsLCD5zar6nSSvSnLfJD9I8q0kXVXXSfLNJLsn6SQ/TvLzSb6wvOb4HT5qOBOo3AYAAACACVRV9RLmVdUTkrw8yecz+m9fKslXk1wnyUeT/GKSvTJC7xMyQu4rd/dX1jB0OFOo3AYAAACAndxGO5Ll8+cluUmS13X3d6rq95K8MsnVk7wlo0XJt5JcIMmxGZXbXxVss6sRbrNTWT1RAwAAAPDTiu2NYPsCSY5Lsn93vz35aYuS22QE3JdOcqXuftraBgw7yG7rHgBsqKrdV07UV1/3eAAAAAB2BiutSJ6a5JNJbpfkyxv7l0zlW0lum+SoJH9eVY+pqt3XMV7YUYTb7BSWk/AJy+fPSfLiqrr7ekcFAAAAsHOoqkpydJKvJzn7yvY9uvuEJVv5ZpLbJPluRtB9vjUMFXYYC0qydpsWQ3hZkqsmeWSS93f3Z9Y6OACYkDZfAHDG21SU9dP7WNgRNo6/pRL7fkkelRFyX29pSbL7SsB9QlX9bJLzdPd/r3XgcCYTbrPTqKqHJtkvyR8k+VB3/7iqzpWx+MHRSb7nRh0ATtlSufOTqtoryXWSnJDkO939sTUPDQCmtSnYvm+SX0pyZJI3dPdH1jo4dkmrx9y29mUE3H+R5AtJfndbAfeOHC+si3CbnUZVPT/JuZPcsbtPXPpuPy3JxZMck+Rx3f2ydY4RAHZmG1VkVXWeJP+RsZjQ+TIWHHp6kud299fWOER2QW6ggbOSZbbxzTIqZi+X5CNJntzdh6x1YOxSNj1MuWeSX0xy0Yzruc909w+rao8k91/+fCnJrVYD7vWMHHY8PbdZi6rabdPXuye5WMZN+B2q6glJ3pFxM/7sJHsleeBShQYAbLLcyPRyo/P6JMcm+ZMkt0/y90kekuRpVXWRNQ6TXUxVnX3l5vteVfW0qvqTqrrKuscGcEZYXYyvqq6RETLeMqOd5pWTnDPJw60ZxRllaS+38d76z0kelOT6SS6b5M1J7lJVF+zunyR5xvLnokneXlUXEGxzVrPHugfAWc+mJ5C/leSz3f2pZWrXW5IclORzSR7a3c9cXldJ/jDjwuFH6xk5AOyclortE6rq7EnOlTE99dnd/Z5l/78nOSLJPyT5ZJJHr2uszK+qzpnk75I8pLuPXLb9S5Jfz1i86ueT/GdVPam7X7GucQKcEVbuXR+cESB+IqON5nFJPlpVt07y0iQPqqp09wvWNVZ2DRvtWKvqoIwWc3fu7ndX1cOS/FqSJyc5e1X981Kp/Ywk50jy+0nOk+Rb6xk5rIfKbXaoTcH285M8Jsndq+rc3f3pJFfIOHnfdiXYvmDGU8pPZ1RyA8BZXlWdbanSzkrF9huT/E+S6yU5auO1S2XPS5I8J8n9q2rvNQyZXcetk9wuycuq6iJLJeMVk9wmyeUzKhr3TPKYqrrj2kYJcBpU1Xmr6j7LA+ONbTdN8rAkd0jyje4+rqp2X9a5+PiyvZPsX1X3Ws/I2ZVU1Q0zZgf82RJsPyijOGHfjOu9xyW5Y1VdaLnOe3ySG3T3F9c1ZlgX4TY71Eqw/ZIkN0xyQJJndfcxS/B9THd/uru/tLzul5P8dZIbJHlEd/9wTUMHgJ1GVV0+yYOT3GPpr50kuyc5NKP3589mrFnx0+nU3f3jJO/KqOw+744eM7uUl2QsYHWxJK9McpMkb0/ynu7+cXe/PskDk/wwyaME3MBk7pMRVp+4saG735LkocuX96iq6yz3tiesBNy3S3LBjOKtn9nRg2aX89Uk/5LksKr6gySPSHKP7j44yZOS/DjjvfZuVfWz3X1Cd397fcOF9RFus8NV1T0yKsruluS13f215c3/Cqv9GavqL5McnOS6SW62XDAAwFlaVV03yWuS3DbJBbr76CTp7h8l+duM9l7HJjmwqs6zqe/ibkm+k+RsO3bU7CqWYoQTkxyYsajVhZI8MskPuvv4jfVRuvvNGX3ej03ysKrad11jBthOz0py8+Wc9ltVdb4k6e6Dkjwqyfcz1rC4Rnd3Tgq4P5FknyR36u7vrWvwzGdpw7rZF5M8v7uPzWg38uIkL1/2fSSjBd25Mx429w4YJuy0hNusw2WSfLW735lkj6q6XpJ3J3lDkg8toXaSHJbRu+w3u/vD6xkqAOw8qupaSV6bsZjQ3bv7icv23ZJkuQH6p4yb70smeUdV3aiqLrdMb31ARpuv96xj/Mxttb3cEug8K8lzk3w7yZ2r6iLd/aOqOtvymjdnLIJ17iT3XpllALDT6u4fLOey22c8TL53VZ132ff3SZ6Y5MJJnrUScJ+4nCM/1d2fX9/omUlV7baxIPjy9bmraq/lYclPuvt7yzoXl0nyM0uf9yTZO8k3Mlq6/kp3f2c9/wLYOdTy/xDsMFV174xqn0dlrDT9+xnTqP81o6fUA5Ps3d2fXlYJPvFkfxgAnEVU1c9lvFd+JGMhv/8z9XTjZqiqzp3kThntv86b5JtJ3pHRquQW3f3j1aASTs2mdVPunOTI7n7bUm12nyR/meRLSW61zMo729IKJ1V1oyRf6u4vrGv8zMc5inWrqvNntCK5f8b76YHd/f1l370z7lu/nOTB3f3eNQ2TCa2+R65se0qSq2e0ljs8yXO6+4NLuH1IxvpkT8ooUrh7RrB90+7+xo4cO+yM9lj3ANh1nUIw/eokV0ryZxmVY/ddnoBv9AX9QsYU1gi22R4ehrAjndzx5jjkTHTxjEqxV3b3tzeCn6q6QJJrJblRkq6qQ7v78Ko6JGOW3p8luUDG++13k5NC8PX8M5jNcl7bCLYPyShG+FBV/ddyLD47o+f7/kleXVW36u6jqmrP7j6+u9+2xuEzoU0PU/ZJcokkX0vy5e7+1FoHxy5pW9dv3f2dqnpikkryV8vrDuzu73f3QVV1YkYV9wFV9btJjt+owIWTsyxU+qqq+mB3P2zZ9vKMNcnekOR7SW6R5C5VtW93v6yq9k/y+oyFwX+Y5OgkvyPYhkG4zZli0wXpDTKqxnbr7td091eS3KeqHp3kRxv9yJab85sk+UqSY9Y0dCZVVbVxQVpVF12qxsoFJmeGlerYvZJcLWOBvu919/sF25yJLp3kIkmOT8YizVX1qxk3OtfMSe3mHlhVd+juQ6vq4Iw+jE9M8qaqul53Hx+9GdkOK++v/5ixyPe+STaC7Y2HLM9aXv6AJK+sqtt191fXNGQmtulhysYi9OdMsmeSI6vqsd39onWOkV3H0tZrt40HvlV1nWXXj7v7A8t57jHZdsD93Kr6cZK3LetewFZcOKPo4E5VdXRGO7nzJ/m9JO/q7l5atz4oySFVdVR3v2NpL3fD5We8r7u/tI7Bw85IWxLOcJuC7X/MmC5zgYyL0kOT/GV3//em77lJkjtnnNBv0N0f3bGjZldRVX+X5Oe6+9brHgu7ppUg5zxJ3pRxfvuFjCqKlyZ55PIQD85QVXX5JEckeUvGsXehjKnSx2YswPzEjODxERkh+HW6+7+XCqG7ZtyUH5PkikvADVu2BD7/kjFF/59XHx6vnBcryX2TPD7JezMqz070oJnTYpkRcMuMtjeHJ7lUkmckuX6Sa3f3+9c3Oma3tHq40Op96fJA+CYZ4eMxGTOOH9XdX1jafT0qY4bKw5M8d2M2FGzVRvFVVV0uY92KvZP8Z8bM9n26+6iV1149yT9mLAR+G3214eSp3OYMtxJsvyjJjZP8ccYJ+2+S3CXJeavq/t39xeV191xes2eSGwq2Oa2qao8kP7fytcptznBLgHOOJG/LmDZ47yQ/SHLZJM9PsldV3XujJyOcEZbz2aeq6g+SvDgj8ElGD8ZDuvv1y9evWELwRyb5mSTp7uOq6p+SnD3J/8tob6L3MadoG/2OL5lx7LxnuTGvlY8nrHx9YJIfJ3mzfsmcVlV18YyHdU9P8tbuPnZ5UPcrGQ/zPr7O8TG3pVr74CS3rqqNtZ4OzHhw8vAk301yxYz3zMtW1X7d/bGqenySn2Q8wDu+qp7uXoPtsfK++emq+vOMgPt6Sb65EWxv9OPu7g9U1WuS3CvJXmscNuz0djv1l8ApW6p0Nm+7e5KrJLnzcsN99yS3yai22CfJM6rqMsvLP5TkqRk9o/5rBwyZXcRyYfpTy3TCw5NcdamqdY7jzPJ7GbNRHpDkLd397pzU5uGI1WB7W+dI2KqN42fj5rm7X5Xx/nqTJNft7rtuBNvLA75khNifybg535jif1ySv09ytbaoH6diU1uIe1TVJZMcl/G+euHkf92gb5z79q+qW3T3id39nO7+zHpGz4w2zl8r75kXTPLLST60BNtXyFhM901J7tXdP6iqP6mqX17PiJnZ0mrpn5N8LMk7l/vSH2RUZr+wuw/NmA31uxmz8x6zfN93kjw5YybU6wTbnBbL++duy/oB98uYlXelGgtKppdFv5eXH5nkxCTnWctgYRKCH06XqjpXkgOr6hor2/bMmJ7/kqU31J9mXADsmzFV+sAkt0ry6Kr6he7+YHe/tLuPXMM/gUlt6rF9iZVdn81YYXqjkmy31e/ZwcNk13X5jNkmH+vuE5dq2hckeWh3P6WqfraqbpecFErC9qhhj40AsUZ/943Q8TMZ/T3ft7EtGQ/4quqySX47yfuTfHnZfuJyzjzOFGpOzab315cneUhG+6WvJ/lmkvtW1aWSk85vVXXhjD6gN6+qs3m/ZXssx9zGArePqarrZsyM+maSKyyzUd6VEWzfcwm7fy1jBssltvlD4WSsPDR+WZKHJfl2Rrj4hxnVsycu+0/o7ndlVHLfusaCkenubyc5oLs/sYbhM6mVsDrJSWtZrATcb0xy16p67LL9hKq6YJLfyFhM93927IhhLtqScHpdOcmfJvmFqnpYdx/R3cdX1XuSvLWqLpTRcuRRSV617Hv18j13TnLuqrr9ygUtbMnKDfWLk9y0qv47yReTfCljcb/bV9Urk/woox+tkJHTZBtT85PRh/EC3f2jqvqdjNYQD+vuJy1B422S3LGqDm+LvbAdquq8PRap6iQ/qdHj86Akl6mqnyQ5rKr+truPWm6UTlzC6z2TXCvJkzKKF/54pTJIz2O2ZON4WT6/eJLdk9ynu49Ytv1DRth9TFU9u7s/UlW/ktH7/VpJHtjdP17L4JnSpmPuWRnFMK/OCBw/nxE+PjFjltQdl4d9P5vkjzLWHfjwekbOrFZnnXT3a5aw+wEZbXAumfyfa793Zsxcuejqz9jR42Zem2ZDPSSjxdcPMtq2fqO7P7O0KHlmkoctD/iOS3J0xnG5j+IEOGXCbU6X7n5PVd0iySuSPKmqHtLdH9oIc6rqShlTub7RJy1edYmMi4RnJ/m8YJvTagl2Xp/krRk98i62fEzGjdBTknyzqj6ccYHwT939hjUMlUktNz8bPbavurQfSZIPJvleVb0t46LzAd399GXfFTJuzj+WpXIWtqKqrpwxG+oZ3f3KpVr7gxn9PY9IcumMhdVuV1W32mgvUmPBoSdlTFk9JsmNlyruPbzHsj1WQsanJLlmxg34J1b2P2x5kPLHSe5cVV9fdu2V5De1ImF7bJolcJWMc9h+Ge29flJV+2ZUa587yb8uD4+vu7zm1hmL0H9tLYNnakvAvUd3/6S7N46t8yR5fFW9u7s/svLyPTNmEgi0OU1WznMvSXKzJEcluUyS30zyoKp6W491Ve6bEXBfJ2Pmyp8keZBCGTh15aEjZ4SVgPtdSR68UuFz9SSHJXluRuXZcUkem+R8Se7a3T9cx3iZ02p1zym85spJDk3y9ozQ+4pJfjWj2uIO3f3JM3mY7CI2qnaWG54XZ1xo7tfdb172/13GDfZ7M1otfTvjpvtpy4+43nJzbmFTtqSqfiPJKzOC7MdlVGDfJ6MKe+Oh8T2SPDTj/fTmSwX3zTP6gb4qyZOX41awzWlSVT+TcSztnVE1dsXlXHb2Hr3bs8xYuVKSX8x4APO6XhYKh+21VGzfKMn5M85rn6xlQbVlZsChSc6RsUjul5Icn2TfTQEknKLNM/E2X59V1a2SPCHJRTJmBhyR5LxJ/jyj3dc1nefYHqvHWI31AQ7KmOl0ZMa96T9nPBy+f5I39VgA/HJJXpixfspNlzY4wKkQbnOarF4cbASOy035y5K8O/874P7LJI/OuBj9YcZCRDdqi0eyHTYdc1fPOI6+keQTPRYV+mmQU1VvTfLZ7t5v+fpsGee747f90+F/2ziequqcSa6W8VDuihmVFg/o7jctr/uHjAqMjaqeEzN64v36clO+rZYmcLKW99LnZSwI+f2M1kp3SLI6pfUPMyq1n97dj1+2nbeXhUwdd5xWK9d0F814UHfHJM/r7j9a9u/pvZQzWlU9KKP9yHmT/G53v2bZvvGQ+fwZhQqXzViI/kvd/fWT+3mw2ab7iP0zZtldPqNK9r3d/ZVl360y1oraO8m3MmYOXDWjKEsLHLZsGw9TNgpgfqO7v7ds+/kk/57x8O7P878D7uNUbMPWCbfZbpsuDu6cEeS8r7u/t1SPvSIj4H5od39wed0fZlQ9/iDJc3ssnABbsqkf4yEZ1bGXzrjo/EqSP1ityK6qVyS5cHdff1s/D07JRpXF0uv4P5N8IaNK7PsZawV8JKO/9muX1980yVUyWn19Msm/q5xlq6rq+knulOTPVs5zv53kbzOqGP+5u++5bF99iHd4ku939802/TwzBdiyU5oRVWORyAMzWi+9sLsfvGx3buMMseme4u4Z570jktyvT1ow1/HG6bLpOPuXjKKFDyU5IWPm3UFJ/m6jrVJV3TrJnyW5SZJrJPlUd/9gDUNnUpvuXR+e8SDlx0nO3t13XrZvFNL8fEbAvUfGQ75/6+4frWfkMC/hNttlGyHjtZO8KMlB3f3NZfstkrw8mwJuOL1WqmT/IqMH6C8leUZGL8arJ/nyUnH24Ix2EVfp7mPXNFwmttKK5EoZNz5fWgLrfZP8ZcaDur/YqODexvernOVUVdUeGVNRL9Xd99s0ffUWGe+v509yl+5+6bJ9o5LxFcu+W7QF/DgNNgU+v5Xk5zKmQT935Ti8WJJnJfm1JAd394OW7afaJgw2O7X3xqq6V5LHJ3lPkkd39+HLdg/tON2q6pkZ7UXu1N3vq6p7ZzzA64wHK09fCbh/P+P9+a5tLQFOo6p6ccYx96mMe9VkFDMctOzfuKa7dMZ57+sZawkcs5YBw8R2W/cAmMtKsP28jEqeP0ly4EawvbzmDUlul3Ej9FdVda11jJX5VVWtfH6FJDfMCBb/rbs/mlEle/4kb0jy9ZUb7WOTXCDJ2XbsiNmFnCdj+vM7eyza10nS3S/KaFFy5SRPrapf39Y3C7bZiqUa8W+XYPucSR5WY6HcjffSu2QsKPTQqrrjxvdV1S9mTNH/nGCb02KpGNsItv8pyVOTHJDxHvuuqrrq8pqvJrlfRsHCHavq2clJ14OwVZuOuT+sqqdV1YHLg5UkSXc/N+MYvG6SA6rqGst2wTZbVlVnr6o7VtWTq2qfqtqzxoKlV80oTHjf0grnmRkL+v11knsluV9VXT5JuvslSW4m2GZ71FhweePzK2bMNP7t7r5mxiz2DyR5QFXdMxn3C0vA/d/L/tsKtuG0EW6zXapqj+VC8/oZfbTftq1FDpab8ttmXDA8uKr22rEjZVZVtXtVXSL5PzczF89YVfo/u/uHVbV3xgKmr0vyR0t/sj+qqnNl9Me72kY/Mzg5qxehmxybMX3wkskIcpYq23T3C5O8NMnFMm6+r7sjxsquo6ousDywS3cfvWy+fUafz79ZCbjflDEL5cJJXlxVL8xYcPLvM2YP/Ony8yqwHVba2/xjxoPjP814oHdoxg3285OsBtz3zag8u0lV/dx6Rs1slpDx4kul/8Yx9y8Zi+JePcnPJ3lNVf3Jxvd097OTPGLZ/8yqutqOHzmzqqrzJHljkv+XcR96Qkaxy+eTHJzkrVV1m4xjcL/lnvWJST6c5PeTPKSqLpMkQka2oqp+ZpldnI01KZYHwfdI8uUk71/2HZ4xG+AbSR6+jYD7S939+TX8E2CXINzmZC0XpHeoqv2XaYIbN0OXTPKLST6y2gNvU5Xtubr7jUl+PcnD9Y1iK5Zg+plJnlFVt9+0e2N2wEWWadLvTvLmjAvTY6vqhhkPVK7S3Z9sq5lzKqrqqkmeXVW/s2n7Hhk3Q0ckuXZV3XKZEv2TqtqtxgKl501yeJJLZfThFjCyJVX1qxnB4ebK/9dmtFzaL+O43Ai4X5vkbhnrW9w6ye5JnpzkqssxuYeqRk7Ntq7pqmqfJNdMco/uPixjMav9Mipnz5nxEOVqVXW27v5akn0zFsv9xnr+Fcykqs6b5ItJbr8y8/PZGT2M79HdN8p4n02S51TVX2x87zJl/6+TXDTj3Aenqk5aK+XHSR6Y5Brd/fbu/sHyIPmFS1HW7yR5S0YbzSzFMN/KWFvl9hkFDnCqlvPcB5P8So2Fb1NVl8yYJfCAJBdJstvGPUJ3v2vZ/vUkD6qq+yzbzfiE00m4zTYtT70PS/KE5c9BVfWBqrpQxsJqldHnOCs34Bv9GX8vyS2WG+639MpCf3BylmPunRk3PZ/LaDWy6jsZfbYfm+S/lv136+5jquoCGTfkeyb57A4bNNOqqp/NqOC5Z5JXV9VLq+ruG9Vly434I5Icl3EOvGXy06n4l85Y1fyhSf45yV2q6vwCRk5NVf1axsySnyR5zWrP9u7+n4zQ++EZx+VqwP2mjGDxXEk+392vW6n0sdAap+hkrunel3E8PTvJ26tqv4wZeftmhIpPz2i/9KQk11yOtaO6+8h1/BuYyxL4fCCj2n9jvYDrJtk7yQO6+51LmP3gjIX7npfkSRtBT5J091OTXL27v7yjx898lsKEf0jytST37O53LrM6f5p3rBRbXSLJJXpZJLKqfiFjNtT1kly8u4/asaNnRst57oiMhedv3d3fSZLlnHXfjJl2103yW93dKwH3u5Psn+TEJPtV1c+sYfiwyxFu838sJ+oPJzk6yR8muVzGzfblMoKcw5P8d0aF2U+fNNZwsYwpONfOCMDhVNXoNfuWjOrs/TKq/b+/EewkydKL7CkZFwnHZVRfHLdMV/3rJL+V5L4qytii72ac55LkXzNaLf1jkv+sqn2r6nLLWgK3zKjSPqSq3rBM4X9dkvN194eTfHv5WYJtTlGNfp8vS3JIkvt093OW7avnuW8neWG2HXC/McmNMqZabyywptKHU3Qq13RPTPLqjNkAf5jxXnro0sf9NRnTqW+UMaPKGhZsycox96Ukv7+0tUnG++XrkryuxhoCD8uo4D4o4/03GW2ZHrHy4767Y0bNLuAiSa6Y5CUZ564k/3d9gOU99X1JLlZVf11Vt85Yb+BXk+yupSFbsXKe+0KSfbv7a5sepHwgo0jmP5L8Y1VtDrjfkzEr7zaOOThjCLf5X5a2EB/OqH69W5J3LKHiMzIqym6S5EoZCw/drKpeWVWXXcLJKyd5XEaPvH+0yBXb4c8yHobsn+RjG5WIKw9OLrR8/cKMG/Ddkjyvqj6X5J8yFi+9SXd/bA1jZzJLdfaJSR6Z8UDl8xl9Px+SEVK/IMnrq+q+GdNUL5cxPf9cGTc/b8+Yyp8kN86oTHO+42QtN9P7ZUxdffJyE1Qn7a5zVtUvLcfmNzKqzx6ecb77mzqp3/u7Viq2PVDhFJ3KNd3BGUHQpZL8XEa/7R9u9AvNqLD9ZMb76+27+7gdO3pmtBxzH0nymSR3Wc51G+evTyX5zFI9e8eMByivXPa9J2MdlY8k+X/LjDwLSbI9rpbkl5O89eQe/K48FD4wyUczZqq8KOM8d6vu/sqOGizz2sZ57qvLddmJVbVXVb2tqu62zF5/SMbM5H/ZRsB9uDaacMbZY90DYKezb8aU+5cv/RVTVXv2WMDvHRk3R99I8qEkZ884YX8gyTFJvpfRquSWywUsbNXVk3y3u/9rdeMyTfoWSfauqiMzprK+oKo+kXGc/kqS9yY5wgUpW7VSxfPNJG/LqJB9Xnf/dVU9M8mdkvxxRrXin2dU2h6U5AlLZW2q6mJV9diMhdeutzG1FU5GZcw6+djGuWq5wblEkntlzBC4eJJPV9X9uvtDyyyBEzOqab+Q0Wc7y/eq2GYrTuma7u1J7prxYO6EjBlR16yxFsH3k9xh+Rkf7+7v7/ihM6l9Mx6YvGyjknFZG+AcGdWyn6iqd2c8WHlvdx+bJFV1peX7H5zk/b2NxerhVOyWlUKDlUKGVZVRxNAZ13Xfyrif/eTGORK2YFvnuROqaq+MIoZjMlrQpbs/XFUPzmjxdXBV3bO7X7m2kcMuTLjNZi/JqGD8i6o6OsljV6p4bpkxPfDr3f29GovCvDIj8D5Xkk8neeNSFQRbslT07JHkXEulzrczKsiek2SfjGPuixlTo/+9qvbp7vdl3CS9dB1jZtfQ3d+tqr/PWIj0VhnB44+q6mUZU1Q3LlD3z1hg7QFJnl5j8dKnJjlfkhuZMcAW7JHRz/NCVXXRjOPqhkmemxFqH5HxoPiaSV5eVddfbphelOSrca7jtDm1a7rvJflSd39zmanyiiQ3zTg+z57kpoJtttPqMXdsdz9qCXwOzzgH7t/d/1NV703ymzUWD/9+kt/LaAH2QcE2p9HHMx7U7ZfkgUsVba1W/6+E3QdnnPv2W8M4md/Jnec+kPG+eoelmrt6+HBVPSjJ3yV5VlW9QVEMnPHKbC82W3pIPTIj0Dmgux9TVY/MWDzt15dFYHZXOcYZpaqulVGBfVhGmH39jDDo4CSPyegV+hsZPd8P6e4/Xs9I2RVV1asyFhHaO6N68f1JfpjktzMW0L1IxloCD9lomVNj4dwPdfcX1jFm5lNV10vyjowg+ycZU6g/njFr4JlVdbaMtQNeluQp3f3QTd+/R1s8ku20xWu6PZbq2utnvNf+IKMizQLNbLdNx9zjMh4eH5vk9km+ssxauXDGrKibZITbxyT57e4+Yi2DZno1FuX7tySXSXLv7n71sv1/VXBX1RWS/E3G+gLPXstgmd4pned608LLy/Xdnhn3Ez/u7i/t4OHCWYJwm23adMJ+d8ZN+N27+6Wbn4KvfM82t8NWVNUNkjwvoxr2PzKmC/7nypTVc2YEQe/o7ruua5zseqrqjzOOt8cl+YOMhyl3XnrlbX7tniuVj7BdqurXMtqMnD/JizPaRXxqZf8lk/xXkqd396PXM0p2NadyTbfbtioc4fRYOebukxFcX6VPWlhy9XW3XfZ/vLu/vHk/bI8aCze/K2MtlAO6+zWb9p8/Y3H66ye5udnGnB5bOc9V1bkzFsw9f5LfUBwIZx7hNierqs6TsaDV/ZK8rrtvu+YhsYtbAuzzdPfXN22vjP7aByd5UXc/xY04p9fqMVRV78roifz2jCrtLzq+ODMsrZjO3t3HbNq+W5KbJ3lWkkd290vWMT52Ta7p2NGWStoHZcwSOKC7H7Oyb1v9kOF0q6rfSPLyjH7aL0zy7Ixe3DdIcruMCtsbdveH1zZIdhmncp47T8Z6KXfOaPN1+HpGCWcNem5zsrr76Kp6YsbiG39RVY9cPWHDGW2p0t6o1F6tkD1fkvtnLFj6suW1gkdOl2Vq9EbAfXCSX86YGaDVCGeapf3DD5KTWo0swfZlkjwqyZFZznNwRnFNx462rM/zpCR7JTlgeb999LJPsM2ZortfX1U3yuhv/JCM4DEZ761fyVgE/KPrGh+7lpM7zy0V20/JWLj5et39obUOFM4ChNucomXBtccl2T3jhN3d/VfrHhe7vo1gu6pumrEq9a2S3NgUQs5IKw9J/jWjqvHaiTZLnLk2jq0l2L5gkt9Mcq+MRfxu2N0nWNuCM5prOna07v5+VW08RHlUVZ3Q3Y9d66DY5XX3B6rq5hmL/v1qxjnvvUmOtGApZ7RtnOf2SHLBCLZhhxJuc6pWTtgnJHl0Vf2ou/963eNi17asOn1YRtX2d5PcQKUFZ5bu/kpVPT7JgVV1k+7+j3WPiV1fVZ0vyceSfDPJR5LcdQm8LR7JmcI1HTvapmPuMVV1vGOOM1t3fyujNckH1j0Wdn2bznMPT3JikmsKtmHHEW6zJcsJ+/FJjs9YiRrOVN39o6raP2Phq1dtayEiOIO9NskrMvpuw5luqaS9eZJLJfn3ZWG/3QXbnJlc07GjOeaAXd1ynntCku8leeW2FqYHzjwWlGS7WACGHU17CNZB5Szr4D2WHcnxxo7mmAN2dc5zsB7CbQAAAAAAprPbugcAAAAAAADba6cKt6vqdlX1N1X1jqr6flV1VR287nEBAAAAALBz2dkWlHxEkqskOSbJkUn2Xu9wAAAAAADYGe1UldtJ/l+SyyU5b5I/XfNYAAAAAADYSe1UldvdfdjG51W1zqEAAAAAALAT29kqtwEAAAAA4FQJtwEAAAAAmM5O1ZbkjHDjG9+41z0Gzlqe8YxnJEnuf//7r3UcnHU45tjRHHPsaI45djTHHOvguGNHc8yxDm9961t31b7DO33+uPH/+sb/+zux03WMqNwGAAAAAGA6wm0AAAAAAKYj3AYAAAAAYDrCbQAAAAAApiPcBgAAAABgOnusewCrqurWSW69fHmR5eN1q+oFy+ff7O4H7uBhAQAAAACwk9mpwu0kv5rkbpu2XWb5kyT/nUS4DQAAAABwFrdTtSXp7gO6u07hz8+ve4wAAAAAAKzfThVuAwAAAADAVgi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmI5wGwAAAACA6Qi3AQAAAACYjnAbAAAAAIDpCLcBAAAAAJiOcBsAAAAAgOkItwEAAAAAmM52hdtV9VtV9caqOrKqflhVn6+ql1XVdbfx2nNX1V9V1Seq6riq+m5VvaWqbnkyP/sSVfXw5ed9tqpOrKquql86rf84AAAAAAB2TVsOt6vqSUn+LcnVkrw+yTOTfDDJ7yZ5V1XdZeW150vyniSPSHJCkr9N8vIkv5Lk36vqftv4K66R5LFJbpukknxv+/85AAAAAACnXVXtvhTtfmEp2v1CVT22qvZY99h2Rafn972l/yBVdZEkD0zy9SRX7u5vrOzbJ8l/JHlMkoOXzQck+eUkr0xyx+7+yfLaCyU5PMlTqup13f2Zlb/mP5PcMMmHu/v7VfXWJDfayvgAAAAAAM4gD05ynyR3S/JfSa6c5IVJfpTkr9Y4rl3Vaf59b7Vy+9LLa9+3GmwnSXcfluToJBda2fx7y8dHbgTby2v/J8lTk5wtyb02/Zwju/sd3f39LY4JAAAAAOCM9mtJXtPdr+nuL3b3vyb51yTXXvO4dlWn+fe91XD7M0mOT3Ktqrrg6o6qumGS8yR588rmiywfP7+Nn7Wx7aZb/LsBAAAAAHaUdybZp6r2TpKqumKSmyR57VpHtUXHH398jjrqqHzuc5/L85///Bx//PHrHtKpOc2/7y21Jenub1fVg5M8LcnHq+pVSb6V5BeT3CrJm5L8ycq3fDPJRZP8QpKPb/pxl1k+7r2VvxsAAAAAYAd6UkYx78er6oSMDPVx3X3Qeod16o4//vjc7na3y9FHH50kedGLXpRDDz00L3/5y7PnnnuueXQn6zT/vre8oGR3PyOj3cgeSf4oyUOS3D7Jl5O8YFO7kn9bPh5QVbtvbKyqCyTZf/lyr6o6x1b/fgAAAACAHeCOSfZNcqckV1s+v3dV3XOto9qCQw455KfB9oajjz46hxxyyJpGtCWn+fdd3b2lv6GqHpTk8UmeleTAJEdlVF8/IcnNkzy5ux+0vPYiSd6b0av7o0nekuScSX43oz/3RZev9+rubdbFrywoednu/uyWBgkAAAAAcDpU1ZeTPKW7n7my7RFJ7t7dv7S+kZ26ffbZ583ZdjvoNx922GG/vqPHsxWn5/e9pbYkVXXjjPLwQ7t7/5VdH6yq2yT5dJIHVNVzu/vz3X1UVV0zySOS/E6Seyf5TkZF919l9N3+3skF2wAAAAAAa3LOJCds2nZCtqMLxrocdthhN1v3GE6D0/z73lK4neS3l4+Hbd7R3cdW1eFJbpPkqlkWjOzu/0ny58ufn6qqfZJUkvdv8e8GAAAAANhRXpPkIVX1hSQfy8g890/yorWOatd1mn/fWw2391o+Xuhk9m9s30ol9h8tH3fqRi8AAAAAwFnSfTO6TxyU5OeSfC3J3yd5zDoHtQs7zb/vLfXcrqo7JPmXJF9PcvXu/srKvt9M8u9JfpTkEt39raraLck5u/uYTT9nv2VgRyS5Vnf/+BT+zrdGz20AAAAAALZhq5XbL0/y5iQ3S/KJqjo0Y0HJK2S0LKkkD+nuby2vP2eSr1fVm5JsBNM3SHKtJJ9LcpttBdtV9YKVL/dePj6pqjaW+PyH7n7nFscMAAAAAMAuakuV20lSVWdLcp8kv5/kihkB9reTHJ7kWd39xk2vfW6S6ye5xLL5cxkh+dM2V3SvfN+pDeYe3f2CLQ0YAAAAAIBd1pbDbQAAAAAA2Fnstu4BAAAAAADA9hJuAwAAAAAwHeE2AAAAAADTEW4DAAAAADAd4TYAAAAAANMRbgMAAAAAMB3hNgAAAAAA0xFuAwAAAAAwHeE2AAAAAADTEW4DAAAAADCd/w/kw6C27BwjMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('3. 전처리 요구사항 - ')\n",
    "\n",
    "print('불필요한 피처 제거 - PassengerId, Name, Ticket')\n",
    "#titanic_feature_tmp = titanic_feature.drop(['PassengerId','Name','Ticket'],axis=1)\n",
    "#display(titanic_feature_tmp)\n",
    "#titanic_feature = titanic_feature_tmp\n",
    "\n",
    "# 함수화\n",
    "# def drop_features(frm):\n",
    "#     frm.drop(['PassengerId', 'Name', 'Ticket'],axis=1,inplace==True)\n",
    "    \n",
    "print('결측값 처리, 시각적 확인 - Age는 평균, Cabin은 N, Embarked는 N')\n",
    "#titanic_feature_tmp['Age'] = titanic_feature['Age'].fillna(np.mean(titanic_feature['Age']))\n",
    "#titanic_feature_tmp['Cabin'] = titanic_feature['Cabin'].fillna('N')\n",
    "#titanic_feature_tmp['Embarked'] = titanic_feature['Embarked'].fillna('N')\n",
    "msno.matrix(titanic_feature)\n",
    "display(titanic_feature)\n",
    "\n",
    "# 함수화\n",
    "# def pre_processing(frm):\n",
    "#     frm['Age'].fillna(frm['Age'].mean(),inplace = True)\n",
    "#     frm['Cabin'].fillna('N',inplace=True)\n",
    "#     frm['Embarked'].fillna('N',inplace=True)\n",
    "#     return frm\n",
    "\n",
    "print('Cabin의 경우 앞 문자 하나에 대해서 레이블 인코딩만 진행!!')\n",
    "print('레이블 인코딩 - Sex, Cabin, Embarked')\n",
    "# sex_encoder = LabelEncoder()\n",
    "# sex_encoder.fit(titanic_feature['Sex'])\n",
    "# titanic_feature['Sex'] = sex_encoder.transform(titanic_feature['Sex'])\n",
    "# print(titanic_feature['Sex'])\n",
    "# print()\n",
    "\n",
    "\n",
    "# cabin_encoder = LabelEncoder()\n",
    "# cabin_encoder.fit(titanic_feature['Cabin'].str[0])\n",
    "# titanic_feature['Cabin'] = cabin_encoder.transform(titanic_feature['Cabin'].str[0])\n",
    "# print(titanic_feature['Cabin'])\n",
    "# print()\n",
    "\n",
    "# embarked_encoder = LabelEncoder()\n",
    "# embarked_encoder.fit(titanic_feature['Embarked'])\n",
    "# titanic_feature['Embarked'] = embarked_encoder.transform(titanic_feature['Embarked'])\n",
    "# print(titanic_feature['Embarked'])\n",
    "# print()\n",
    "\n",
    "# 함수화\n",
    "# def label_encoder(frm):\n",
    "#     frm['Cabin'] = frm['Cabin'].str[:1]\n",
    "#     features = ['Sex','Cabin','Embarked']\n",
    "#     for feature in features:\n",
    "#         encoder = LabelEncoder()\n",
    "#         frm[feature] = encoder.fit_transform(frm[feature])\n",
    "#     return frm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0fbd9ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습과 테스트 분리 - \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((712, 8), (179, 8), (712,), (179,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('학습과 테스트 분리 - ')\n",
    "print()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(titanic_feature,\n",
    "                                                   titanic_target,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=200) \n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d33c332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train,Y_train)\n",
    "lr_Y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5b4a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train,Y_train)\n",
    "dt_Y_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a90a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_eval(target, prediction):\n",
    "    print('accuracy - ',accuracy_score(target,prediction))\n",
    "    print('recall - ',recall_score(target,prediction))\n",
    "    print('precision - ',precision_score(target,prediction))\n",
    "    print('f1 score - ',f1_score(target,prediction))\n",
    "    print()\n",
    "    print('confusion_matrix - \\n',confusion_matrix(target,prediction))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7b488c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - \n",
      "\n",
      "accuracy -  0.770949720670391\n",
      "recall -  0.7066666666666667\n",
      "precision -  0.7361111111111112\n",
      "f1 score -  0.7210884353741497\n",
      "\n",
      "confusion_matrix - \n",
      " [[85 19]\n",
      " [22 53]]\n",
      "\n",
      "acc -  0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression - ')\n",
    "print()\n",
    "metrics_eval(Y_test,lr_Y_pred)\n",
    "print()\n",
    "print('acc - ',(90+54)/(90+54+14+21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60640eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier - \n",
      "\n",
      "accuracy -  0.6983240223463687\n",
      "recall -  0.5466666666666666\n",
      "precision -  0.6721311475409836\n",
      "f1 score -  0.6029411764705882\n",
      "\n",
      "confusion_matrix - \n",
      " [[84 20]\n",
      " [34 41]]\n"
     ]
    }
   ],
   "source": [
    "print('DecisionTreeClassifier - ')\n",
    "print()\n",
    "metrics_eval(Y_test,dt_Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e8f4a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('교차검증 - ')\n",
    "fold = KFold(n_splits = 20)\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "result = cross_validate(lr_model,X_train,Y_train,\n",
    "                       cv=fold,\n",
    "                       scoring = scoring)\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "239c0c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7990476190476192"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ae53997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e2ae221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유방암 관련 데이터 - 정확도, 재현율(실제 P를 N으로 예측하면 안되기 때문에)\n",
      "재현율은 실제 양성을 양성으로 예측한 비율이 높아야 성능이 좋은 모델\n"
     ]
    }
   ],
   "source": [
    "print('유방암 관련 데이터 - 정확도, 재현율(실제 P를 N으로 예측하면 안되기 때문에)')\n",
    "print('재현율은 실제 양성을 양성으로 예측한 비율이 높아야 성능이 좋은 모델')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7ef1c2b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 프레임 만들기(feature,target) 포함\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. target에 대한 균형 여부 확인\n",
      "1    357\n",
      "0    212\n",
      "Name: target, dtype: int64\n",
      "\n",
      "3. 데이터셋 분리\n",
      "(455, 30) (114, 30) (455,) (114,)\n",
      "\n",
      "4. RandomForestClassifier\n",
      "[1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1\n",
      " 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1\n",
      " 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 0 1]\n",
      "\n",
      "5. 평가지표 확인\n",
      "accuracy -  0.9473684210526315\n",
      "recall -  0.9736842105263158\n",
      "precision -  0.9487179487179487\n",
      "f1 score -  0.9610389610389611\n",
      "\n",
      "confusion_matrix - \n",
      " [[34  4]\n",
      " [ 2 74]]\n"
     ]
    }
   ],
   "source": [
    "print(\"1. 프레임 만들기(feature,target) 포함\")\n",
    "cancer_frm = pd.DataFrame(data=cancer.data,\n",
    "                         columns=cancer.feature_names)\n",
    "cancer_frm['target'] = cancer.target\n",
    "display(cancer_frm)\n",
    "print()\n",
    "\n",
    "print(\"2. target에 대한 균형 여부 확인\")\n",
    "print(cancer_frm['target'].value_counts())\n",
    "print()\n",
    "\n",
    "print(\"3. 데이터셋 분리\")\n",
    "X_train,X_test,y_train,y_test = train_test_split(cancer.data,\n",
    "                                                cancer.target,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=200)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print()\n",
    "\n",
    "print(\"4. RandomForestClassifier\")\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train,y_train)\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "print(rf_y_pred)\n",
    "print()\n",
    "\n",
    "print(\"5. 평가지표 확인\")\n",
    "metrics_eval(y_test,rf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f1aff1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1'])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('교차검증 - ')\n",
    "fold = KFold(n_splits = 20)\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "result = cross_validate(rf_model,X_train,y_train,\n",
    "                       cv=fold,\n",
    "                       scoring = scoring)\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b097fe73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9748495744451626"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['test_recall'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "00a87473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "재현율을 높이기 위한 방법으로 - GridSearchCV를 이용한 파라미터 튜닝!!\n",
      "n_estimators - tree 갯수를 의미\n",
      "max_features - 최대 선택할 피처의 수를 의미\n",
      "max_depth - 최대 선택할 트리의 깊이를 의미\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [4, 6, 8], 'max_features': [6, 8, 15, 20],\n",
       "                         'n_estimators': [50, 100, 150, 200]},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"재현율을 높이기 위한 방법으로 - GridSearchCV를 이용한 파라미터 튜닝!!\")\n",
    "print(\"n_estimators - tree 갯수를 의미\")\n",
    "print(\"max_features - 최대 선택할 피처의 수를 의미\")\n",
    "print(\"max_depth - 최대 선택할 트리의 깊이를 의미\")\n",
    "param = {\n",
    "    'n_estimators' : [50,100,150,200],\n",
    "    'max_features' : [6,8,15,20],\n",
    "    'max_depth' : [4,6,8]\n",
    "}\n",
    "\n",
    "grid_search_model = GridSearchCV(rf_model,\n",
    "                                 param,\n",
    "                                 cv=20,\n",
    "                                 refit=True,\n",
    "                                 scoring='recall')\n",
    "grid_search_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bad3a824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.07106135, 0.1359056 , 0.20484273, 0.26984712, 0.07501738,\n",
       "        0.14685321, 0.22158803, 0.29023335, 0.0945891 , 0.19040447,\n",
       "        0.28868432, 0.38828149, 0.11124908, 0.22574351, 0.35203818,\n",
       "        0.44529002, 0.07881953, 0.14765193, 0.2134357 , 0.28582541,\n",
       "        0.07886081, 0.1546818 , 0.23464968, 0.31240098, 0.10425513,\n",
       "        0.20419905, 0.30909313, 0.40527005, 0.12127992, 0.23804294,\n",
       "        0.35995862, 0.48300387, 0.07663218, 0.14241992, 0.21547526,\n",
       "        0.29030126, 0.08142186, 0.1575632 , 0.23538195, 0.32269247,\n",
       "        0.10643386, 0.2048944 , 0.3059007 , 0.41048689, 0.12029337,\n",
       "        0.24339019, 0.36280725, 0.47674335]),\n",
       " 'std_fit_time': array([0.00422616, 0.00590502, 0.00662259, 0.00849268, 0.00307574,\n",
       "        0.00490223, 0.00728604, 0.00733186, 0.00315962, 0.00502205,\n",
       "        0.01268881, 0.01356139, 0.00253425, 0.00894696, 0.03586969,\n",
       "        0.01107306, 0.00943573, 0.00808456, 0.00626548, 0.00834197,\n",
       "        0.00373593, 0.00338331, 0.00566318, 0.0102054 , 0.00548137,\n",
       "        0.0062889 , 0.00874816, 0.00923162, 0.0074204 , 0.00523729,\n",
       "        0.00988573, 0.01723423, 0.00720496, 0.00551311, 0.00753158,\n",
       "        0.0115972 , 0.00440125, 0.00764948, 0.00760934, 0.01727711,\n",
       "        0.00502222, 0.00551876, 0.00562555, 0.00789326, 0.00487567,\n",
       "        0.01170148, 0.01290378, 0.01070218]),\n",
       " 'mean_score_time': array([0.00483996, 0.00798008, 0.01206731, 0.0159448 , 0.00458488,\n",
       "        0.00836906, 0.01175234, 0.01489596, 0.00434107, 0.00813575,\n",
       "        0.01176889, 0.01551065, 0.0045891 , 0.00829539, 0.01266922,\n",
       "        0.01546274, 0.00503699, 0.00810359, 0.01176871, 0.01506442,\n",
       "        0.004691  , 0.00822772, 0.01189668, 0.01534805, 0.00503111,\n",
       "        0.00805265, 0.01177142, 0.01524681, 0.00453392, 0.00829068,\n",
       "        0.0125398 , 0.01578795, 0.00503639, 0.00828494, 0.01186199,\n",
       "        0.01565641, 0.00471953, 0.00792911, 0.01219776, 0.01534213,\n",
       "        0.00461292, 0.0084281 , 0.01165079, 0.01519759, 0.00474683,\n",
       "        0.00817792, 0.01178693, 0.01463704]),\n",
       " 'std_score_time': array([0.00090461, 0.00070079, 0.00093649, 0.00259321, 0.00049079,\n",
       "        0.00085812, 0.00080853, 0.00140744, 0.00047684, 0.00069916,\n",
       "        0.00086825, 0.00143103, 0.000494  , 0.00063925, 0.00163862,\n",
       "        0.0018187 , 0.00136257, 0.00070115, 0.00086996, 0.00098859,\n",
       "        0.000946  , 0.00053556, 0.0014186 , 0.00107247, 0.00139082,\n",
       "        0.00067891, 0.00120133, 0.00100471, 0.0005865 , 0.00060964,\n",
       "        0.00172555, 0.00106162, 0.0011949 , 0.0015191 , 0.00099486,\n",
       "        0.00164444, 0.00053202, 0.0006681 , 0.00118674, 0.00092091,\n",
       "        0.00056945, 0.00128347, 0.00091556, 0.00137901, 0.00069848,\n",
       "        0.00067773, 0.00121195, 0.00073929]),\n",
       " 'param_max_depth': masked_array(data=[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[6, 6, 6, 6, 8, 8, 8, 8, 15, 15, 15, 15, 20, 20, 20, 20,\n",
       "                    6, 6, 6, 6, 8, 8, 8, 8, 15, 15, 15, 15, 20, 20, 20, 20,\n",
       "                    6, 6, 6, 6, 8, 8, 8, 8, 15, 15, 15, 15, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 150, 200, 50, 100, 150, 200, 50, 100, 150,\n",
       "                    200, 50, 100, 150, 200, 50, 100, 150, 200, 50, 100,\n",
       "                    150, 200, 50, 100, 150, 200, 50, 100, 150, 200, 50,\n",
       "                    100, 150, 200, 50, 100, 150, 200, 50, 100, 150, 200,\n",
       "                    50, 100, 150, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 4, 'max_features': 6, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 6, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 6, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 6, 'n_estimators': 200},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 8, 'n_estimators': 200},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 15, 'n_estimators': 200},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 150},\n",
       "  {'max_depth': 4, 'max_features': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 6, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 8, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 15, 'n_estimators': 200},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 150},\n",
       "  {'max_depth': 6, 'max_features': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 6, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 8, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 15, 'n_estimators': 200},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 150},\n",
       "  {'max_depth': 8, 'max_features': 20, 'n_estimators': 200}],\n",
       " 'split0_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split1_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split3_test_score': array([0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        1.        , 0.92857143, 0.92857143, 1.        , 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 1.        , 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 1.        ,\n",
       "        0.92857143, 1.        , 0.92857143]),\n",
       " 'split4_test_score': array([0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 1.        , 1.        ,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 1.        , 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143]),\n",
       " 'split5_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 1.        , 1.        , 1.        ,\n",
       "        0.92857143, 1.        , 0.92857143, 1.        , 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.92857143, 1.        , 1.        , 1.        ,\n",
       "        0.92857143, 1.        , 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143]),\n",
       " 'split6_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split7_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split8_test_score': array([0.92857143, 0.92857143, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.92857143,\n",
       "        0.92857143, 1.        , 0.85714286, 0.92857143, 0.92857143,\n",
       "        0.85714286, 0.92857143, 1.        , 0.92857143, 1.        ,\n",
       "        0.92857143, 0.92857143, 1.        , 1.        , 0.92857143,\n",
       "        0.85714286, 1.        , 1.        , 0.92857143, 0.92857143,\n",
       "        0.85714286, 0.85714286, 0.92857143, 0.92857143, 1.        ,\n",
       "        1.        , 1.        , 0.92857143, 1.        , 1.        ,\n",
       "        0.92857143, 0.92857143, 1.        , 1.        , 0.92857143,\n",
       "        0.92857143, 0.85714286, 1.        ]),\n",
       " 'split9_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.92857143, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split10_test_score': array([0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143]),\n",
       " 'split11_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split12_test_score': array([0.92857143, 0.92857143, 0.92857143, 0.92857143, 1.        ,\n",
       "        0.92857143, 1.        , 0.92857143, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        1.        , 1.        , 0.92857143, 0.92857143, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 1.        , 0.92857143, 0.92857143, 0.92857143,\n",
       "        1.        , 1.        , 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 1.        , 1.        ]),\n",
       " 'split13_test_score': array([0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.85714286, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143]),\n",
       " 'split14_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split15_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split16_test_score': array([0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.92857143,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 1.        , 0.92857143, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.92857143, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split17_test_score': array([0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.85714286, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.85714286, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 1.        ,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.85714286, 0.92857143, 0.92857143,\n",
       "        0.92857143, 1.        , 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143]),\n",
       " 'split18_test_score': array([0.92857143, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.92857143, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.92857143, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split19_test_score': array([0.92857143, 0.92857143, 1.        , 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 1.        , 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 1.        ,\n",
       "        0.92857143, 1.        , 1.        , 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 1.        , 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143]),\n",
       " 'mean_test_score': array([0.96428571, 0.96785714, 0.975     , 0.97142857, 0.975     ,\n",
       "        0.975     , 0.975     , 0.975     , 0.97142857, 0.96785714,\n",
       "        0.97142857, 0.975     , 0.96785714, 0.97142857, 0.97142857,\n",
       "        0.96785714, 0.96071429, 0.97142857, 0.97142857, 0.97857143,\n",
       "        0.96785714, 0.97857143, 0.97142857, 0.97857143, 0.975     ,\n",
       "        0.96785714, 0.975     , 0.97142857, 0.975     , 0.97142857,\n",
       "        0.96785714, 0.96785714, 0.96785714, 0.97142857, 0.97142857,\n",
       "        0.97142857, 0.97142857, 0.96785714, 0.97142857, 0.975     ,\n",
       "        0.97142857, 0.975     , 0.97142857, 0.97142857, 0.97142857,\n",
       "        0.96785714, 0.97142857, 0.975     ]),\n",
       " 'std_test_score': array([0.03571429, 0.03553527, 0.03406926, 0.03499271, 0.03406926,\n",
       "        0.03406926, 0.03406926, 0.03406926, 0.04164966, 0.03553527,\n",
       "        0.03499271, 0.03406926, 0.04778246, 0.03499271, 0.03499271,\n",
       "        0.04210652, 0.04210652, 0.03499271, 0.03499271, 0.03273268,\n",
       "        0.03553527, 0.03273268, 0.03499271, 0.03273268, 0.03406926,\n",
       "        0.04210652, 0.03406926, 0.03499271, 0.03406926, 0.03499271,\n",
       "        0.04210652, 0.04210652, 0.04210652, 0.03499271, 0.03499271,\n",
       "        0.03499271, 0.03499271, 0.03553527, 0.03499271, 0.03406926,\n",
       "        0.03499271, 0.03406926, 0.03499271, 0.03499271, 0.03499271,\n",
       "        0.03553527, 0.04164966, 0.03406926]),\n",
       " 'rank_test_score': array([47, 38,  6, 30,  6,  6,  6,  6, 16, 38, 16,  6, 36, 16, 16, 38, 48,\n",
       "        30, 16,  2, 46,  1, 16,  2,  4, 38,  6, 30,  6, 16, 38, 38, 36, 16,\n",
       "        30, 30, 16, 38, 30,  6, 16,  4, 16, 16, 16, 38, 16,  6])}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b6b989aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 8, 'n_estimators': 100}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "de5ee001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9785714285714286"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6ed1d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_estimator = grid_search_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "79dd3329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy -  0.9385964912280702\n",
      "recall -  0.9736842105263158\n",
      "precision -  0.9367088607594937\n",
      "f1 score -  0.9548387096774194\n",
      "\n",
      "confusion_matrix - \n",
      " [[33  5]\n",
      " [ 2 74]]\n"
     ]
    }
   ],
   "source": [
    "best_y_pred = rf_estimator.predict(X_test)\n",
    "metrics_eval(y_test,best_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1265d36",
   "metadata": {},
   "source": [
    "#### 정밀도와 재현율을 임의로 조절하는 모델을 생성해야 하는 경우\n",
    "- 분류 임계값이 낮을수록 Positive를 예측할 확률이 높아져 재현율이 증가한다.\n",
    "- predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c7f08490",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [\n",
    "    [-1,-1,2],\n",
    "    [2,0,0],\n",
    "    [0,1.1,1.2]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9bb4edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "holder = Binarizer(threshold=1.1)\n",
    "print(holder.fit_transform(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "637d9c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터 로드\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('1. 데이터 로드')\n",
    "print()\n",
    "titanic_frm = pd.read_csv('data/titanic_train.csv')\n",
    "display(titanic_frm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b2d6513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. target, feature로 데이터 분리\n",
      "target type -  <class 'pandas.core.series.Series'>\n",
      "feature type -  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print('2. target, feature로 데이터 분리')\n",
    "\n",
    "titanic_target = titanic_frm['Survived']\n",
    "titanic_feature = titanic_frm.drop(['Survived'],axis=1)\n",
    "\n",
    "print('target type - ',type(titanic_target))\n",
    "print('feature type - ',type(titanic_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f7b04437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. 전처리 요구사항 - \n",
      "불필요한 피처 제거 - PassengerId, Name, Ticket\n",
      "결측값 처리, 시각적 확인 - Age는 평균, Cabin은 N, Embarked는 N\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>N</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex        Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0         3    male  22.000000      1      0   7.2500     N        S\n",
       "1         1  female  38.000000      1      0  71.2833   C85        C\n",
       "2         3  female  26.000000      0      0   7.9250     N        S\n",
       "3         1  female  35.000000      1      0  53.1000  C123        S\n",
       "4         3    male  35.000000      0      0   8.0500     N        S\n",
       "..      ...     ...        ...    ...    ...      ...   ...      ...\n",
       "886       2    male  27.000000      0      0  13.0000     N        S\n",
       "887       1  female  19.000000      0      0  30.0000   B42        S\n",
       "888       3  female  29.699118      1      2  23.4500     N        S\n",
       "889       1    male  26.000000      0      0  30.0000  C148        C\n",
       "890       3    male  32.000000      0      0   7.7500     N        Q\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabin의 경우 앞 문자 하나에 대해서 레이블 인코딩만 진행!!\n",
      "레이블 인코딩 - Sex, Cabin, Embarked\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "886    1\n",
      "887    0\n",
      "888    0\n",
      "889    1\n",
      "890    1\n",
      "Name: Sex, Length: 891, dtype: int32\n",
      "\n",
      "0      7\n",
      "1      2\n",
      "2      7\n",
      "3      2\n",
      "4      7\n",
      "      ..\n",
      "886    7\n",
      "887    1\n",
      "888    7\n",
      "889    2\n",
      "890    7\n",
      "Name: Cabin, Length: 891, dtype: int32\n",
      "\n",
      "0      3\n",
      "1      0\n",
      "2      3\n",
      "3      3\n",
      "4      3\n",
      "      ..\n",
      "886    3\n",
      "887    3\n",
      "888    3\n",
      "889    0\n",
      "890    2\n",
      "Name: Embarked, Length: 891, dtype: int32\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('3. 전처리 요구사항 - ')\n",
    "\n",
    "print('불필요한 피처 제거 - PassengerId, Name, Ticket')\n",
    "#titanic_feature_tmp = titanic_feature.drop(['PassengerId','Name','Ticket'],axis=1)\n",
    "#display(titanic_feature_tmp)\n",
    "#titanic_feature = titanic_feature_tmp\n",
    "\n",
    "# 함수화\n",
    "# def drop_features(frm):\n",
    "#     frm.drop(['PassengerId', 'Name', 'Ticket'],axis=1,inplace==True)\n",
    "    \n",
    "print('결측값 처리, 시각적 확인 - Age는 평균, Cabin은 N, Embarked는 N')\n",
    "#titanic_feature_tmp['Age'] = titanic_feature['Age'].fillna(np.mean(titanic_feature['Age']))\n",
    "#titanic_feature_tmp['Cabin'] = titanic_feature['Cabin'].fillna('N')\n",
    "#titanic_feature_tmp['Embarked'] = titanic_feature['Embarked'].fillna('N')\n",
    "msno.matrix(titanic_feature)\n",
    "display(titanic_feature)\n",
    "\n",
    "# 함수화\n",
    "# def pre_processing(frm):\n",
    "#     frm['Age'].fillna(frm['Age'].mean(),inplace = True)\n",
    "#     frm['Cabin'].fillna('N',inplace=True)\n",
    "#     frm['Embarked'].fillna('N',inplace=True)\n",
    "#     return frm\n",
    "\n",
    "print('Cabin의 경우 앞 문자 하나에 대해서 레이블 인코딩만 진행!!')\n",
    "print('레이블 인코딩 - Sex, Cabin, Embarked')\n",
    "# sex_encoder = LabelEncoder()\n",
    "# sex_encoder.fit(titanic_feature['Sex'])\n",
    "# titanic_feature['Sex'] = sex_encoder.transform(titanic_feature['Sex'])\n",
    "# print(titanic_feature['Sex'])\n",
    "# print()\n",
    "\n",
    "\n",
    "# cabin_encoder = LabelEncoder()\n",
    "# cabin_encoder.fit(titanic_feature['Cabin'].str[0])\n",
    "# titanic_feature['Cabin'] = cabin_encoder.transform(titanic_feature['Cabin'].str[0])\n",
    "# print(titanic_feature['Cabin'])\n",
    "# print()\n",
    "\n",
    "# embarked_encoder = LabelEncoder()\n",
    "# embarked_encoder.fit(titanic_feature['Embarked'])\n",
    "# titanic_feature['Embarked'] = embarked_encoder.transform(titanic_feature['Embarked'])\n",
    "# print(titanic_feature['Embarked'])\n",
    "# print()\n",
    "\n",
    "# 함수화\n",
    "# def label_encoder(frm):\n",
    "#     frm['Cabin'] = frm['Cabin'].str[:1]\n",
    "#     features = ['Sex','Cabin','Embarked']\n",
    "#     for feature in features:\n",
    "#         encoder = LabelEncoder()\n",
    "#         frm[feature] = encoder.fit_transform(frm[feature])\n",
    "#     return frm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "130dc0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습과 테스트 분리 - \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((712, 8), (179, 8), (712,), (179,))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('학습과 테스트 분리 - ')\n",
    "print()\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_feature,\n",
    "                                                   titanic_target,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=200) \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f90ebdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train,y_train)\n",
    "y_pred = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ad7a7ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "확률 예측값 - predict_proba()\n",
      "type -  <class 'numpy.ndarray'>\n",
      "shape -  (179, 2)\n"
     ]
    }
   ],
   "source": [
    "print('확률 예측값 - predict_proba()')\n",
    "predict_proba_result = logistic_model.predict_proba(X_test)\n",
    "print('type - ',type(predict_proba_result))\n",
    "print('shape - ',predict_proba_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3d284b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7272949 , 0.2727051 ],\n",
       "       [0.93336369, 0.06663631],\n",
       "       [0.89663676, 0.10336324],\n",
       "       [0.88745661, 0.11254339],\n",
       "       [0.30430919, 0.69569081],\n",
       "       [0.51209263, 0.48790737],\n",
       "       [0.20815816, 0.79184184],\n",
       "       [0.92998276, 0.07001724],\n",
       "       [0.56455692, 0.43544308],\n",
       "       [0.86329244, 0.13670756],\n",
       "       [0.95599234, 0.04400766],\n",
       "       [0.5480135 , 0.4519865 ],\n",
       "       [0.23679097, 0.76320903],\n",
       "       [0.02373194, 0.97626806],\n",
       "       [0.39265073, 0.60734927],\n",
       "       [0.49422346, 0.50577654],\n",
       "       [0.95984231, 0.04015769],\n",
       "       [0.04717747, 0.95282253],\n",
       "       [0.81117657, 0.18882343],\n",
       "       [0.7109387 , 0.2890613 ],\n",
       "       [0.5624596 , 0.4375404 ],\n",
       "       [0.84901312, 0.15098688],\n",
       "       [0.34035798, 0.65964202],\n",
       "       [0.87383234, 0.12616766],\n",
       "       [0.92877144, 0.07122856],\n",
       "       [0.95429044, 0.04570956],\n",
       "       [0.05145843, 0.94854157],\n",
       "       [0.76491478, 0.23508522],\n",
       "       [0.38584081, 0.61415919],\n",
       "       [0.86337399, 0.13662601],\n",
       "       [0.31444744, 0.68555256],\n",
       "       [0.38251097, 0.61748903],\n",
       "       [0.35063124, 0.64936876],\n",
       "       [0.9138755 , 0.0861245 ],\n",
       "       [0.37377857, 0.62622143],\n",
       "       [0.94480607, 0.05519393],\n",
       "       [0.2698151 , 0.7301849 ],\n",
       "       [0.19550333, 0.80449667],\n",
       "       [0.78882671, 0.21117329],\n",
       "       [0.66231359, 0.33768641],\n",
       "       [0.91392988, 0.08607012],\n",
       "       [0.9018641 , 0.0981359 ],\n",
       "       [0.66032413, 0.33967587],\n",
       "       [0.06621641, 0.93378359],\n",
       "       [0.95471365, 0.04528635],\n",
       "       [0.4009913 , 0.5990087 ],\n",
       "       [0.8888191 , 0.1111809 ],\n",
       "       [0.43149662, 0.56850338],\n",
       "       [0.89397005, 0.10602995],\n",
       "       [0.9366428 , 0.0633572 ],\n",
       "       [0.61197046, 0.38802954],\n",
       "       [0.06731123, 0.93268877],\n",
       "       [0.04401707, 0.95598293],\n",
       "       [0.34715869, 0.65284131],\n",
       "       [0.02431285, 0.97568715],\n",
       "       [0.25139318, 0.74860682],\n",
       "       [0.19000771, 0.80999229],\n",
       "       [0.06938199, 0.93061801],\n",
       "       [0.3992519 , 0.6007481 ],\n",
       "       [0.9338733 , 0.0661267 ],\n",
       "       [0.16490426, 0.83509574],\n",
       "       [0.97143194, 0.02856806],\n",
       "       [0.5767186 , 0.4232814 ],\n",
       "       [0.24279953, 0.75720047],\n",
       "       [0.8355797 , 0.1644203 ],\n",
       "       [0.87832736, 0.12167264],\n",
       "       [0.91225442, 0.08774558],\n",
       "       [0.61829932, 0.38170068],\n",
       "       [0.43730321, 0.56269679],\n",
       "       [0.93225627, 0.06774373],\n",
       "       [0.89665521, 0.10334479],\n",
       "       [0.89171472, 0.10828528],\n",
       "       [0.76700997, 0.23299003],\n",
       "       [0.36222619, 0.63777381],\n",
       "       [0.47071156, 0.52928844],\n",
       "       [0.67337331, 0.32662669],\n",
       "       [0.88285171, 0.11714829],\n",
       "       [0.90572094, 0.09427906],\n",
       "       [0.11367904, 0.88632096],\n",
       "       [0.2785189 , 0.7214811 ],\n",
       "       [0.93799652, 0.06200348],\n",
       "       [0.94639205, 0.05360795],\n",
       "       [0.19692921, 0.80307079],\n",
       "       [0.75898861, 0.24101139],\n",
       "       [0.12659743, 0.87340257],\n",
       "       [0.86328502, 0.13671498],\n",
       "       [0.11174926, 0.88825074],\n",
       "       [0.31998687, 0.68001313],\n",
       "       [0.9338733 , 0.0661267 ],\n",
       "       [0.86913048, 0.13086952],\n",
       "       [0.93056637, 0.06943363],\n",
       "       [0.18417731, 0.81582269],\n",
       "       [0.08236155, 0.91763845],\n",
       "       [0.22466551, 0.77533449],\n",
       "       [0.28882111, 0.71117889],\n",
       "       [0.85945022, 0.14054978],\n",
       "       [0.74960328, 0.25039672],\n",
       "       [0.3992519 , 0.6007481 ],\n",
       "       [0.82458846, 0.17541154],\n",
       "       [0.16571545, 0.83428455],\n",
       "       [0.08340999, 0.91659001],\n",
       "       [0.94333245, 0.05666755],\n",
       "       [0.52853967, 0.47146033],\n",
       "       [0.0503179 , 0.9496821 ],\n",
       "       [0.91392988, 0.08607012],\n",
       "       [0.89842813, 0.10157187],\n",
       "       [0.06295226, 0.93704774],\n",
       "       [0.3304783 , 0.6695217 ],\n",
       "       [0.93311892, 0.06688108],\n",
       "       [0.90811727, 0.09188273],\n",
       "       [0.41341416, 0.58658584],\n",
       "       [0.89415457, 0.10584543],\n",
       "       [0.29123813, 0.70876187],\n",
       "       [0.94564321, 0.05435679],\n",
       "       [0.80450233, 0.19549767],\n",
       "       [0.05521353, 0.94478647],\n",
       "       [0.75365021, 0.24634979],\n",
       "       [0.26202241, 0.73797759],\n",
       "       [0.34564854, 0.65435146],\n",
       "       [0.87814996, 0.12185004],\n",
       "       [0.40259531, 0.59740469],\n",
       "       [0.41366454, 0.58633546],\n",
       "       [0.93721569, 0.06278431],\n",
       "       [0.8040008 , 0.1959992 ],\n",
       "       [0.91519657, 0.08480343],\n",
       "       [0.75898861, 0.24101139],\n",
       "       [0.36057368, 0.63942632],\n",
       "       [0.94484119, 0.05515881],\n",
       "       [0.57793281, 0.42206719],\n",
       "       [0.82348117, 0.17651883],\n",
       "       [0.02184918, 0.97815082],\n",
       "       [0.65765964, 0.34234036],\n",
       "       [0.52128004, 0.47871996],\n",
       "       [0.94292661, 0.05707339],\n",
       "       [0.87825907, 0.12174093],\n",
       "       [0.92160439, 0.07839561],\n",
       "       [0.31432676, 0.68567324],\n",
       "       [0.21015306, 0.78984694],\n",
       "       [0.94130314, 0.05869686],\n",
       "       [0.68696466, 0.31303534],\n",
       "       [0.93583481, 0.06416519],\n",
       "       [0.92160439, 0.07839561],\n",
       "       [0.92058971, 0.07941029],\n",
       "       [0.22841409, 0.77158591],\n",
       "       [0.76723447, 0.23276553],\n",
       "       [0.82269422, 0.17730578],\n",
       "       [0.86118878, 0.13881122],\n",
       "       [0.45465906, 0.54534094],\n",
       "       [0.91392988, 0.08607012],\n",
       "       [0.91494389, 0.08505611],\n",
       "       [0.50573014, 0.49426986],\n",
       "       [0.27160756, 0.72839244],\n",
       "       [0.12521269, 0.87478731],\n",
       "       [0.34046534, 0.65953466],\n",
       "       [0.76966037, 0.23033963],\n",
       "       [0.13459352, 0.86540648],\n",
       "       [0.05703758, 0.94296242],\n",
       "       [0.77455384, 0.22544616],\n",
       "       [0.43129802, 0.56870198],\n",
       "       [0.99538622, 0.00461378],\n",
       "       [0.85240859, 0.14759141],\n",
       "       [0.91389939, 0.08610061],\n",
       "       [0.93778512, 0.06221488],\n",
       "       [0.28837406, 0.71162594],\n",
       "       [0.85273431, 0.14726569],\n",
       "       [0.73927549, 0.26072451],\n",
       "       [0.63219896, 0.36780104],\n",
       "       [0.87811232, 0.12188768],\n",
       "       [0.85273431, 0.14726569],\n",
       "       [0.40630554, 0.59369446],\n",
       "       [0.95440815, 0.04559185],\n",
       "       [0.96460093, 0.03539907],\n",
       "       [0.8230248 , 0.1769752 ],\n",
       "       [0.45602133, 0.54397867],\n",
       "       [0.91389939, 0.08610061],\n",
       "       [0.33188929, 0.66811071],\n",
       "       [0.12852898, 0.87147102],\n",
       "       [0.84592947, 0.15407053],\n",
       "       [0.95243845, 0.04756155]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predict_proba_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ab15f684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(y_pred)\n",
    "y_pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "993c5cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7272949 , 0.2727051 , 0.        ],\n",
       "       [0.93336369, 0.06663631, 0.        ],\n",
       "       [0.89663676, 0.10336324, 0.        ],\n",
       "       [0.88745661, 0.11254339, 0.        ],\n",
       "       [0.30430919, 0.69569081, 1.        ],\n",
       "       [0.51209263, 0.48790737, 0.        ],\n",
       "       [0.20815816, 0.79184184, 1.        ],\n",
       "       [0.92998276, 0.07001724, 0.        ],\n",
       "       [0.56455692, 0.43544308, 0.        ],\n",
       "       [0.86329244, 0.13670756, 0.        ],\n",
       "       [0.95599234, 0.04400766, 0.        ],\n",
       "       [0.5480135 , 0.4519865 , 0.        ],\n",
       "       [0.23679097, 0.76320903, 1.        ],\n",
       "       [0.02373194, 0.97626806, 1.        ],\n",
       "       [0.39265073, 0.60734927, 1.        ],\n",
       "       [0.49422346, 0.50577654, 1.        ],\n",
       "       [0.95984231, 0.04015769, 0.        ],\n",
       "       [0.04717747, 0.95282253, 1.        ],\n",
       "       [0.81117657, 0.18882343, 0.        ],\n",
       "       [0.7109387 , 0.2890613 , 0.        ],\n",
       "       [0.5624596 , 0.4375404 , 0.        ],\n",
       "       [0.84901312, 0.15098688, 0.        ],\n",
       "       [0.34035798, 0.65964202, 1.        ],\n",
       "       [0.87383234, 0.12616766, 0.        ],\n",
       "       [0.92877144, 0.07122856, 0.        ],\n",
       "       [0.95429044, 0.04570956, 0.        ],\n",
       "       [0.05145843, 0.94854157, 1.        ],\n",
       "       [0.76491478, 0.23508522, 0.        ],\n",
       "       [0.38584081, 0.61415919, 1.        ],\n",
       "       [0.86337399, 0.13662601, 0.        ],\n",
       "       [0.31444744, 0.68555256, 1.        ],\n",
       "       [0.38251097, 0.61748903, 1.        ],\n",
       "       [0.35063124, 0.64936876, 1.        ],\n",
       "       [0.9138755 , 0.0861245 , 0.        ],\n",
       "       [0.37377857, 0.62622143, 1.        ],\n",
       "       [0.94480607, 0.05519393, 0.        ],\n",
       "       [0.2698151 , 0.7301849 , 1.        ],\n",
       "       [0.19550333, 0.80449667, 1.        ],\n",
       "       [0.78882671, 0.21117329, 0.        ],\n",
       "       [0.66231359, 0.33768641, 0.        ],\n",
       "       [0.91392988, 0.08607012, 0.        ],\n",
       "       [0.9018641 , 0.0981359 , 0.        ],\n",
       "       [0.66032413, 0.33967587, 0.        ],\n",
       "       [0.06621641, 0.93378359, 1.        ],\n",
       "       [0.95471365, 0.04528635, 0.        ],\n",
       "       [0.4009913 , 0.5990087 , 1.        ],\n",
       "       [0.8888191 , 0.1111809 , 0.        ],\n",
       "       [0.43149662, 0.56850338, 1.        ],\n",
       "       [0.89397005, 0.10602995, 0.        ],\n",
       "       [0.9366428 , 0.0633572 , 0.        ],\n",
       "       [0.61197046, 0.38802954, 0.        ],\n",
       "       [0.06731123, 0.93268877, 1.        ],\n",
       "       [0.04401707, 0.95598293, 1.        ],\n",
       "       [0.34715869, 0.65284131, 1.        ],\n",
       "       [0.02431285, 0.97568715, 1.        ],\n",
       "       [0.25139318, 0.74860682, 1.        ],\n",
       "       [0.19000771, 0.80999229, 1.        ],\n",
       "       [0.06938199, 0.93061801, 1.        ],\n",
       "       [0.3992519 , 0.6007481 , 1.        ],\n",
       "       [0.9338733 , 0.0661267 , 0.        ],\n",
       "       [0.16490426, 0.83509574, 1.        ],\n",
       "       [0.97143194, 0.02856806, 0.        ],\n",
       "       [0.5767186 , 0.4232814 , 0.        ],\n",
       "       [0.24279953, 0.75720047, 1.        ],\n",
       "       [0.8355797 , 0.1644203 , 0.        ],\n",
       "       [0.87832736, 0.12167264, 0.        ],\n",
       "       [0.91225442, 0.08774558, 0.        ],\n",
       "       [0.61829932, 0.38170068, 0.        ],\n",
       "       [0.43730321, 0.56269679, 1.        ],\n",
       "       [0.93225627, 0.06774373, 0.        ],\n",
       "       [0.89665521, 0.10334479, 0.        ],\n",
       "       [0.89171472, 0.10828528, 0.        ],\n",
       "       [0.76700997, 0.23299003, 0.        ],\n",
       "       [0.36222619, 0.63777381, 1.        ],\n",
       "       [0.47071156, 0.52928844, 1.        ],\n",
       "       [0.67337331, 0.32662669, 0.        ],\n",
       "       [0.88285171, 0.11714829, 0.        ],\n",
       "       [0.90572094, 0.09427906, 0.        ],\n",
       "       [0.11367904, 0.88632096, 1.        ],\n",
       "       [0.2785189 , 0.7214811 , 1.        ],\n",
       "       [0.93799652, 0.06200348, 0.        ],\n",
       "       [0.94639205, 0.05360795, 0.        ],\n",
       "       [0.19692921, 0.80307079, 1.        ],\n",
       "       [0.75898861, 0.24101139, 0.        ],\n",
       "       [0.12659743, 0.87340257, 1.        ],\n",
       "       [0.86328502, 0.13671498, 0.        ],\n",
       "       [0.11174926, 0.88825074, 1.        ],\n",
       "       [0.31998687, 0.68001313, 1.        ],\n",
       "       [0.9338733 , 0.0661267 , 0.        ],\n",
       "       [0.86913048, 0.13086952, 0.        ],\n",
       "       [0.93056637, 0.06943363, 0.        ],\n",
       "       [0.18417731, 0.81582269, 1.        ],\n",
       "       [0.08236155, 0.91763845, 1.        ],\n",
       "       [0.22466551, 0.77533449, 1.        ],\n",
       "       [0.28882111, 0.71117889, 1.        ],\n",
       "       [0.85945022, 0.14054978, 0.        ],\n",
       "       [0.74960328, 0.25039672, 0.        ],\n",
       "       [0.3992519 , 0.6007481 , 1.        ],\n",
       "       [0.82458846, 0.17541154, 0.        ],\n",
       "       [0.16571545, 0.83428455, 1.        ],\n",
       "       [0.08340999, 0.91659001, 1.        ],\n",
       "       [0.94333245, 0.05666755, 0.        ],\n",
       "       [0.52853967, 0.47146033, 0.        ],\n",
       "       [0.0503179 , 0.9496821 , 1.        ],\n",
       "       [0.91392988, 0.08607012, 0.        ],\n",
       "       [0.89842813, 0.10157187, 0.        ],\n",
       "       [0.06295226, 0.93704774, 1.        ],\n",
       "       [0.3304783 , 0.6695217 , 1.        ],\n",
       "       [0.93311892, 0.06688108, 0.        ],\n",
       "       [0.90811727, 0.09188273, 0.        ],\n",
       "       [0.41341416, 0.58658584, 1.        ],\n",
       "       [0.89415457, 0.10584543, 0.        ],\n",
       "       [0.29123813, 0.70876187, 1.        ],\n",
       "       [0.94564321, 0.05435679, 0.        ],\n",
       "       [0.80450233, 0.19549767, 0.        ],\n",
       "       [0.05521353, 0.94478647, 1.        ],\n",
       "       [0.75365021, 0.24634979, 0.        ],\n",
       "       [0.26202241, 0.73797759, 1.        ],\n",
       "       [0.34564854, 0.65435146, 1.        ],\n",
       "       [0.87814996, 0.12185004, 0.        ],\n",
       "       [0.40259531, 0.59740469, 1.        ],\n",
       "       [0.41366454, 0.58633546, 1.        ],\n",
       "       [0.93721569, 0.06278431, 0.        ],\n",
       "       [0.8040008 , 0.1959992 , 0.        ],\n",
       "       [0.91519657, 0.08480343, 0.        ],\n",
       "       [0.75898861, 0.24101139, 0.        ],\n",
       "       [0.36057368, 0.63942632, 1.        ],\n",
       "       [0.94484119, 0.05515881, 0.        ],\n",
       "       [0.57793281, 0.42206719, 0.        ],\n",
       "       [0.82348117, 0.17651883, 0.        ],\n",
       "       [0.02184918, 0.97815082, 1.        ],\n",
       "       [0.65765964, 0.34234036, 0.        ],\n",
       "       [0.52128004, 0.47871996, 0.        ],\n",
       "       [0.94292661, 0.05707339, 0.        ],\n",
       "       [0.87825907, 0.12174093, 0.        ],\n",
       "       [0.92160439, 0.07839561, 0.        ],\n",
       "       [0.31432676, 0.68567324, 1.        ],\n",
       "       [0.21015306, 0.78984694, 1.        ],\n",
       "       [0.94130314, 0.05869686, 0.        ],\n",
       "       [0.68696466, 0.31303534, 0.        ],\n",
       "       [0.93583481, 0.06416519, 0.        ],\n",
       "       [0.92160439, 0.07839561, 0.        ],\n",
       "       [0.92058971, 0.07941029, 0.        ],\n",
       "       [0.22841409, 0.77158591, 1.        ],\n",
       "       [0.76723447, 0.23276553, 0.        ],\n",
       "       [0.82269422, 0.17730578, 0.        ],\n",
       "       [0.86118878, 0.13881122, 0.        ],\n",
       "       [0.45465906, 0.54534094, 1.        ],\n",
       "       [0.91392988, 0.08607012, 0.        ],\n",
       "       [0.91494389, 0.08505611, 0.        ],\n",
       "       [0.50573014, 0.49426986, 0.        ],\n",
       "       [0.27160756, 0.72839244, 1.        ],\n",
       "       [0.12521269, 0.87478731, 1.        ],\n",
       "       [0.34046534, 0.65953466, 1.        ],\n",
       "       [0.76966037, 0.23033963, 0.        ],\n",
       "       [0.13459352, 0.86540648, 1.        ],\n",
       "       [0.05703758, 0.94296242, 1.        ],\n",
       "       [0.77455384, 0.22544616, 0.        ],\n",
       "       [0.43129802, 0.56870198, 1.        ],\n",
       "       [0.99538622, 0.00461378, 0.        ],\n",
       "       [0.85240859, 0.14759141, 0.        ],\n",
       "       [0.91389939, 0.08610061, 0.        ],\n",
       "       [0.93778512, 0.06221488, 0.        ],\n",
       "       [0.28837406, 0.71162594, 1.        ],\n",
       "       [0.85273431, 0.14726569, 0.        ],\n",
       "       [0.73927549, 0.26072451, 0.        ],\n",
       "       [0.63219896, 0.36780104, 0.        ],\n",
       "       [0.87811232, 0.12188768, 0.        ],\n",
       "       [0.85273431, 0.14726569, 0.        ],\n",
       "       [0.40630554, 0.59369446, 1.        ],\n",
       "       [0.95440815, 0.04559185, 0.        ],\n",
       "       [0.96460093, 0.03539907, 0.        ],\n",
       "       [0.8230248 , 0.1769752 , 0.        ],\n",
       "       [0.45602133, 0.54397867, 1.        ],\n",
       "       [0.91389939, 0.08610061, 0.        ],\n",
       "       [0.33188929, 0.66811071, 1.        ],\n",
       "       [0.12852898, 0.87147102, 1.        ],\n",
       "       [0.84592947, 0.15407053, 0.        ],\n",
       "       [0.95243845, 0.04756155, 0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_prob_concat = np.concatenate([predict_proba_result,y_pred.reshape(-1,1)],axis=1)\n",
    "display(pred_prob_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e39667e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_th = 0.3\n",
    "predict_proba_positive = predict_proba_result[:,1].reshape(-1,1)\n",
    "user_pred = Binarizer(threshold = user_th).fit_transform(predict_proba_positive)\n",
    "display(user_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "595572e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default - \n",
      "\n",
      "accuracy -  0.770949720670391\n",
      "recall -  0.7066666666666667\n",
      "precision -  0.7361111111111112\n",
      "f1 score -  0.7210884353741497\n",
      "\n",
      "confusion_matrix - \n",
      " [[85 19]\n",
      " [22 53]]\n",
      "\n",
      "user thres = 0.3 - \n",
      "\n",
      "accuracy -  0.7653631284916201\n",
      "recall -  0.8133333333333334\n",
      "precision -  0.6853932584269663\n",
      "f1 score -  0.7439024390243902\n",
      "\n",
      "confusion_matrix - \n",
      " [[76 28]\n",
      " [14 61]]\n"
     ]
    }
   ],
   "source": [
    "print('default - ')\n",
    "print()\n",
    "metrics_eval(y_test,y_pred)\n",
    "print()\n",
    "\n",
    "print('user thres = 0.3 - ')\n",
    "print()\n",
    "metrics_eval(y_test,user_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e963081",
   "metadata": {},
   "source": [
    "#### trade-off 시각화\n",
    "- precision_recall_curve(실제값, 예측 확률값): 임계값 변화에 따른 평가지표 반환\n",
    "- 반환값: 정밀도, 재현율, 임계값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0c66c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision type -  <class 'numpy.ndarray'>\n",
      "recall type -  <class 'numpy.ndarray'>\n",
      "th type -  <class 'numpy.ndarray'>\n",
      "precision shape -  (166,)\n",
      "recall shape -  (166,)\n",
      "th shape -  (165,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.43352601, 0.43023256, 0.43274854, 0.43529412, 0.43786982,\n",
       "       0.44047619, 0.44311377, 0.43975904, 0.43636364, 0.43902439,\n",
       "       0.43558282, 0.4382716 , 0.44099379, 0.44375   , 0.44025157,\n",
       "       0.44303797, 0.44871795, 0.4516129 , 0.45454545, 0.45751634,\n",
       "       0.46052632, 0.45695364, 0.46      , 0.45945946, 0.46258503,\n",
       "       0.46575342, 0.46896552, 0.47887324, 0.48571429, 0.48201439,\n",
       "       0.48550725, 0.48905109, 0.49264706, 0.4962963 , 0.5       ,\n",
       "       0.5037594 , 0.5       , 0.49618321, 0.5       , 0.50387597,\n",
       "       0.5078125 , 0.51181102, 0.51587302, 0.52      , 0.51612903,\n",
       "       0.5203252 , 0.52459016, 0.52892562, 0.53333333, 0.52941176,\n",
       "       0.53389831, 0.53846154, 0.54310345, 0.54782609, 0.55752212,\n",
       "       0.5625    , 0.55855856, 0.56363636, 0.56880734, 0.57407407,\n",
       "       0.57943925, 0.58490566, 0.59047619, 0.59615385, 0.60194175,\n",
       "       0.60784314, 0.61386139, 0.62      , 0.62626263, 0.63265306,\n",
       "       0.63917526, 0.64583333, 0.65957447, 0.65591398, 0.66304348,\n",
       "       0.67032967, 0.67777778, 0.68539326, 0.68181818, 0.67816092,\n",
       "       0.6744186 , 0.67058824, 0.67857143, 0.68674699, 0.68292683,\n",
       "       0.69135802, 0.7       , 0.70886076, 0.70512821, 0.71428571,\n",
       "       0.71052632, 0.72      , 0.71621622, 0.7260274 , 0.73611111,\n",
       "       0.73239437, 0.74285714, 0.73913043, 0.73529412, 0.74626866,\n",
       "       0.75757576, 0.75384615, 0.765625  , 0.76190476, 0.75806452,\n",
       "       0.75409836, 0.76666667, 0.79310345, 0.80701754, 0.80357143,\n",
       "       0.81818182, 0.81481481, 0.81132075, 0.82692308, 0.82352941,\n",
       "       0.84      , 0.83673469, 0.85416667, 0.85106383, 0.84782609,\n",
       "       0.84444444, 0.86363636, 0.86046512, 0.85714286, 0.85365854,\n",
       "       0.85      , 0.84615385, 0.86842105, 0.89189189, 0.88888889,\n",
       "       0.88571429, 0.88235294, 0.90909091, 0.90625   , 0.90322581,\n",
       "       0.9       , 0.93103448, 0.96428571, 0.96296296, 0.96153846,\n",
       "       0.96      , 0.95833333, 0.95652174, 0.95454545, 0.95238095,\n",
       "       0.95      , 0.94736842, 0.94444444, 0.94117647, 0.9375    ,\n",
       "       0.93333333, 0.92857143, 0.92307692, 0.91666667, 0.90909091,\n",
       "       0.9       , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.98666667, 0.98666667, 0.98666667, 0.98666667,\n",
       "       0.98666667, 0.98666667, 0.97333333, 0.96      , 0.96      ,\n",
       "       0.94666667, 0.94666667, 0.94666667, 0.94666667, 0.93333333,\n",
       "       0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "       0.93333333, 0.92      , 0.92      , 0.90666667, 0.90666667,\n",
       "       0.90666667, 0.90666667, 0.90666667, 0.90666667, 0.89333333,\n",
       "       0.89333333, 0.89333333, 0.89333333, 0.89333333, 0.89333333,\n",
       "       0.89333333, 0.88      , 0.86666667, 0.86666667, 0.86666667,\n",
       "       0.86666667, 0.86666667, 0.86666667, 0.86666667, 0.85333333,\n",
       "       0.85333333, 0.85333333, 0.85333333, 0.85333333, 0.84      ,\n",
       "       0.84      , 0.84      , 0.84      , 0.84      , 0.84      ,\n",
       "       0.84      , 0.82666667, 0.82666667, 0.82666667, 0.82666667,\n",
       "       0.82666667, 0.82666667, 0.82666667, 0.82666667, 0.82666667,\n",
       "       0.82666667, 0.82666667, 0.82666667, 0.82666667, 0.82666667,\n",
       "       0.82666667, 0.82666667, 0.82666667, 0.81333333, 0.81333333,\n",
       "       0.81333333, 0.81333333, 0.81333333, 0.8       , 0.78666667,\n",
       "       0.77333333, 0.76      , 0.76      , 0.76      , 0.74666667,\n",
       "       0.74666667, 0.74666667, 0.74666667, 0.73333333, 0.73333333,\n",
       "       0.72      , 0.72      , 0.70666667, 0.70666667, 0.70666667,\n",
       "       0.69333333, 0.69333333, 0.68      , 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.65333333, 0.65333333, 0.64      , 0.62666667,\n",
       "       0.61333333, 0.61333333, 0.61333333, 0.61333333, 0.6       ,\n",
       "       0.6       , 0.58666667, 0.57333333, 0.57333333, 0.56      ,\n",
       "       0.56      , 0.54666667, 0.54666667, 0.53333333, 0.52      ,\n",
       "       0.50666667, 0.50666667, 0.49333333, 0.48      , 0.46666667,\n",
       "       0.45333333, 0.44      , 0.44      , 0.44      , 0.42666667,\n",
       "       0.41333333, 0.4       , 0.4       , 0.38666667, 0.37333333,\n",
       "       0.36      , 0.36      , 0.36      , 0.34666667, 0.33333333,\n",
       "       0.32      , 0.30666667, 0.29333333, 0.28      , 0.26666667,\n",
       "       0.25333333, 0.24      , 0.22666667, 0.21333333, 0.2       ,\n",
       "       0.18666667, 0.17333333, 0.16      , 0.14666667, 0.13333333,\n",
       "       0.12      , 0.12      , 0.10666667, 0.09333333, 0.08      ,\n",
       "       0.06666667, 0.05333333, 0.04      , 0.02666667, 0.01333333,\n",
       "       0.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.04559185, 0.04570956, 0.04756155, 0.05360795, 0.05435679,\n",
       "       0.05515881, 0.05519393, 0.05666755, 0.05707339, 0.05869686,\n",
       "       0.06200348, 0.06221488, 0.06278431, 0.0633572 , 0.06416519,\n",
       "       0.0661267 , 0.06663631, 0.06688108, 0.06774373, 0.06943363,\n",
       "       0.07001724, 0.07122856, 0.07839561, 0.07941029, 0.08480343,\n",
       "       0.08505611, 0.08607012, 0.08610061, 0.0861245 , 0.08774558,\n",
       "       0.09188273, 0.09427906, 0.0981359 , 0.10157187, 0.10334479,\n",
       "       0.10336324, 0.10584543, 0.10602995, 0.10828528, 0.1111809 ,\n",
       "       0.11254339, 0.11714829, 0.12167264, 0.12174093, 0.12185004,\n",
       "       0.12188768, 0.12616766, 0.13086952, 0.13662601, 0.13670756,\n",
       "       0.13671498, 0.13881122, 0.14054978, 0.14726569, 0.14759141,\n",
       "       0.15098688, 0.15407053, 0.1644203 , 0.17541154, 0.17651883,\n",
       "       0.1769752 , 0.17730578, 0.18882343, 0.19549767, 0.1959992 ,\n",
       "       0.21117329, 0.22544616, 0.23033963, 0.23276553, 0.23299003,\n",
       "       0.23508522, 0.24101139, 0.24634979, 0.25039672, 0.26072451,\n",
       "       0.2727051 , 0.2890613 , 0.31303534, 0.32662669, 0.33768641,\n",
       "       0.33967587, 0.34234036, 0.36780104, 0.38170068, 0.38802954,\n",
       "       0.42206719, 0.4232814 , 0.43544308, 0.4375404 , 0.4519865 ,\n",
       "       0.47146033, 0.47871996, 0.48790737, 0.49426986, 0.50577654,\n",
       "       0.52928844, 0.54397867, 0.54534094, 0.56269679, 0.56850338,\n",
       "       0.56870198, 0.58633546, 0.58658584, 0.59369446, 0.59740469,\n",
       "       0.5990087 , 0.6007481 , 0.60734927, 0.61415919, 0.61748903,\n",
       "       0.62622143, 0.63777381, 0.63942632, 0.64936876, 0.65284131,\n",
       "       0.65435146, 0.65953466, 0.65964202, 0.66811071, 0.6695217 ,\n",
       "       0.68001313, 0.68555256, 0.68567324, 0.69569081, 0.70876187,\n",
       "       0.71117889, 0.71162594, 0.7214811 , 0.72839244, 0.7301849 ,\n",
       "       0.73797759, 0.74860682, 0.75720047, 0.76320903, 0.77158591,\n",
       "       0.77533449, 0.78984694, 0.79184184, 0.80307079, 0.80449667,\n",
       "       0.80999229, 0.81582269, 0.83428455, 0.83509574, 0.86540648,\n",
       "       0.87147102, 0.87340257, 0.87478731, 0.88632096, 0.88825074,\n",
       "       0.91659001, 0.91763845, 0.93061801, 0.93268877, 0.93378359,\n",
       "       0.93704774, 0.94296242, 0.94478647, 0.94854157, 0.9496821 ,\n",
       "       0.95282253, 0.95598293, 0.97568715, 0.97626806, 0.97815082])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_proba_positive = predict_proba_result[:,1]\n",
    "precision, recall, th = precision_recall_curve(y_test,predict_proba_positive)\n",
    "print('precision type - ',type(precision))\n",
    "print('recall type - ',type(recall))\n",
    "print('th type - ',type(th))\n",
    "print('precision shape - ',precision.shape)\n",
    "print('recall shape - ',recall.shape)\n",
    "print('th shape - ',th.shape)\n",
    "\n",
    "display(precision, recall, th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5107957b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.xlabel('threshold ratio')\n",
    "plt.ylabel('precision and recall value')\n",
    "\n",
    "\n",
    "plt.plot(th,precision[0:th.shape[0]],linestyle='--',label='precision')\n",
    "plt.plot(th,recall[0:th.shape[0]],linestyle='-',label='recall')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fccac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3307d974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f18c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eea1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
